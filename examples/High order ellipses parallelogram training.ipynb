{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Wavefront set extractor using tensorflow high order Ellipses and Parallelogram</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dense.shearlab as shearlab\n",
    "import dense.batchgen as bg\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 1024\n",
    "nClasses = 90\n",
    "nDistr = 20\n",
    "size_patch = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = size\n",
    "cols = size\n",
    "nScales = 4\n",
    "shearletSystem = shearlab.getshearletsystem2D(rows,cols,nScales);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create several data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "array1, label1 = bg.gen_batch_smooth(size, nClasses, nDistr, shearletSystem, size_patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "array2, label2 = bg.gen_batch_smooth(size, nClasses, nDistr, shearletSystem, size_patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "array3, label3 = bg.gen_batch_smooth(size, nClasses, nDistr, shearletSystem, size_patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "array4, label4 = bg.gen_batch_smooth(size, nClasses, nDistr, shearletSystem, size_patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "array5, label5 = bg.gen_batch_smooth(size, nClasses, nDistr, shearletSystem, size_patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "array6, label6 = bg.gen_batch_smooth(size, nClasses, nDistr, shearletSystem, size_patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "array7, label7 = bg.gen_batch_smooth(size, nClasses, nDistr, shearletSystem, size_patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "array8, label8 = bg.gen_batch_smooth(size, nClasses, nDistr, shearletSystem, size_patch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate the arrays and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.concatenate((array1,array2,array3,array4, array5, array6, array8))\n",
    "label = np.concatenate((label1,label2,label3,label4, label5, label6, label8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saving the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an hdf5 file\n",
    "with h5py.File(\"array512ellipsesparalel_highorder.h5\") as f:\n",
    "    # create a dataset for your movie\n",
    "    dst = f.create_dataset(\"array\", shape=(array.shape[0], array.shape[1], \n",
    "                                           array.shape[2],array.shape[3]),\n",
    "                           dtype=np.float64)\n",
    "    for frame in range(array.shape[0]):\n",
    "        dst[frame] = array[frame,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an hdf5 file\n",
    "with h5py.File(\"label512ellipsesparalel_highorder.h5\") as f:\n",
    "    # create a dataset for your movie\n",
    "    dst_label = f.create_dataset(\"label\", shape=(label.shape[0], label.shape[1]),\n",
    "                           dtype=np.float64)\n",
    "    for frame in range(label.shape[0]):\n",
    "        dst_label[frame] = label[frame,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the data\n",
    "with h5py.File(\"array512ellipsesparalel_highorder.h5\", 'r') as h5:\n",
    "    array = h5[\"array\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the data\n",
    "with h5py.File(\"label512ellipsesparalel_highorder.h5\", 'r') as h5:\n",
    "    label = h5[\"label\"][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do some random permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutations = np.random.permutation(array.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = array[permutations,:,:,:]\n",
    "label = label[permutations,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(187684, 20, 20, 49)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(187684, 91)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying the second angle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create several data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_angle(label,angle):\n",
    "    return label[angle] == 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_test(array, label, angle):\n",
    "    # Extract the position of the elements with that angle\n",
    "    labels_angle = [extract_angle(labeli,angle) for labeli in label]\n",
    "    # Generating the labels and arrays\n",
    "    label_angle = np.ones(sum(labels_angle))\n",
    "    array_angle = array[labels_angle]\n",
    "    label_noangle = np.zeros(sum(labels_angle))\n",
    "    array_noangle = array[~np.array(labels_angle)]\n",
    "    # Subsampling the arrays without that angle\n",
    "    array_noangle = array_noangle[0:sum(labels_angle)]\n",
    "    # Creating the test, training and validation\n",
    "    X = np.concatenate((array_angle,array_noangle))\n",
    "    y = np.concatenate((label_angle,label_noangle))\n",
    "    # Permutations\n",
    "    permutations = np.random.permutation(X.shape[0])\n",
    "    X = X[permutations]\n",
    "    y = y[permutations]\n",
    "    # Train test\n",
    "    X_train = X[0:int(X.shape[0]*0.8-1)]\n",
    "    y_train = y[0:int(y.shape[0]*0.8-1)]\n",
    "    # Test set\n",
    "    X_test = X[int(X.shape[0]*0.8):(X.shape[0]-1)]\n",
    "    y_test = y[int(y.shape[0]*0.8):(y.shape[0]-1)]\n",
    "    # Now validation\n",
    "    X_valid = X_train[int(X_train.shape[0]*0.8):(X_train.shape[0]-1)]\n",
    "    y_valid = y_train[int(y_train.shape[0]*0.8):(y_train.shape[0]-1)]\n",
    "    X_train = X_train[0:int(X_train.shape[0]*0.8-1)]\n",
    "    y_train = y_train[0:int(y_train.shape[0]*0.8-1)]\n",
    "    \n",
    "    return X_train, X_test, X_valid, y_train, y_test, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(187684, 91)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification of second angle\n",
    "angle = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, X_valid, y_train, y_test, y_valid = generate_training_test(array, label, angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2990, 20, 20, 49),\n",
       " (935, 20, 20, 49),\n",
       " (747, 20, 20, 49),\n",
       " (2990,),\n",
       " (935,),\n",
       " (747,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, X_valid.shape, y_train.shape, y_test.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an hdf5 file\n",
    "with h5py.File('angle2ellipsesparalel_highorder.h5') as f:\n",
    "    # create a dataset for your movie\n",
    "    X_trainf = f.create_dataset(\"X_train\", shape=(X_train.shape[0], X_train.shape[1], \n",
    "                                           X_train.shape[2],X_train.shape[3]),\n",
    "                           dtype=np.float64)\n",
    "    for frame in range(X_train.shape[0]):\n",
    "        X_trainf[frame] = X_train[frame,:,:,:]\n",
    "        \n",
    "    X_validf = f.create_dataset(\"X_valid\", shape=(X_valid.shape[0], X_valid.shape[1], \n",
    "                                           X_valid.shape[2],X_valid.shape[3]),\n",
    "                           dtype=np.float64)\n",
    "    for frame in range(X_valid.shape[0]):\n",
    "        X_validf[frame] = X_valid[frame,:,:,:]\n",
    "    \n",
    "    X_testf = f.create_dataset(\"X_test\", shape=(X_test.shape[0], X_test.shape[1], \n",
    "                                                 X_test.shape[2],X_test.shape[3]),\n",
    "                           dtype=np.float64)\n",
    "    for frame in range(X_test.shape[0]):\n",
    "        X_testf[frame] = X_test[frame,:,:,:]\n",
    "    \n",
    "    y_trainf = f.create_dataset(\"y_train\", shape=(y_train.shape[0],),\n",
    "                           dtype=np.float64)\n",
    "    for frame in range(y_train.shape[0]):\n",
    "        y_trainf[frame] = y_train[frame]\n",
    "    \n",
    "    y_validf = f.create_dataset(\"y_valid\", shape=(y_valid.shape[0],),\n",
    "                           dtype=np.float64)\n",
    "    for frame in range(y_valid.shape[0]):\n",
    "        y_validf[frame] = y_valid[frame]\n",
    "\n",
    "    y_testf = f.create_dataset(\"y_test\", shape=(y_test.shape[0],),\n",
    "                           dtype=np.float64)\n",
    "    for frame in range(y_test.shape[0]):\n",
    "        y_testf[frame] = y_test[frame]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the data\n",
    "with h5py.File(\"angle2ellipsesparalel_highorder.h5\", 'r') as h5:\n",
    "    X_train = h5[\"X_train\"][:]\n",
    "    X_test = h5[\"X_test\"][:]\n",
    "    X_valid = h5[\"X_valid\"][:]\n",
    "    y_train = h5[\"y_train\"][:]\n",
    "    y_test = h5[\"y_test\"][:]\n",
    "    y_valid = h5[\"y_valid\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train.astype('float32')\n",
    "X_valid = X_valid.astype('float32')\n",
    "y_test = y_test.astype('float32')\n",
    "y_train = y_train.astype('float32')\n",
    "y_valid = y_valid.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2990, 20, 20, 49),\n",
       " (935, 20, 20, 49),\n",
       " (747, 20, 20, 49),\n",
       " (2990,),\n",
       " (935,),\n",
       " (747,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " X_train.shape, X_test.shape, X_valid.shape, y_train.shape, y_test.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create an architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adler.tensorflow import prelu, cosine_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picking GPU 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import adler\n",
    "adler.util.gpu.setup_one_gpu()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "#name = os.path.splitext(os.path.basename(__file__))[0]\n",
    "name = os.path.splitext(os.getcwd())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To categorical**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes = 2)\n",
    "y_test = to_categorical(y_test, num_classes = 2)\n",
    "y_valid = to_categorical(y_valid, num_classes = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = X_train.shape[1]\n",
    "height = X_train.shape[2]\n",
    "channels = X_train.shape[3]\n",
    "nLabel = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Weight Initialization\n",
    "# Create lots of weights and biases & Initialize with a small positive number as we will use ReLU\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "## Convolution and Pooling\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME') \n",
    "\n",
    "## Pooling: max pooling over 2x2 blocks\n",
    "def max_pool_2x2(x): \n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Architecture**: 4 convolutional layers and 2 fully connected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layers = 4\n",
    "fully_connected = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_conv1 (?, 20, 20, 196)\n",
      "h_pool1 (?, 20, 20, 196)\n",
      "h_conv2 (?, 20, 20, 784)\n",
      "h_pool2 (?, 10, 10, 784)\n",
      "h_conv3 (?, 10, 10, 1568)\n",
      "h_pool3 (?, 5, 5, 1568)\n",
      "h_conv4 (?, 5, 5, 3136)\n",
      "h_pool4 (?, 3, 3, 3136)\n",
      "h_pool4_flat (?, 28224)\n",
      "WARNING:tensorflow:From <ipython-input-20-c4b298deb12a>:102: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # Placeholders\n",
    "    x = tf.placeholder(tf.float32, shape=(None, width, height,channels))\n",
    "    y_ = tf.placeholder(tf.float32, shape=(None, nLabel))\n",
    "    \n",
    "    ## First Convolutional Layer\n",
    "    W_conv1 = weight_variable([3, 3, 49, 49*4])\n",
    "    b_conv1 = bias_variable([49*4])\n",
    "    #Convolution\n",
    "    h_conv1 = tf.nn.relu(conv2d(x, W_conv1) + b_conv1)\n",
    "    print('h_conv1',h_conv1.shape)\n",
    "    \n",
    "    # Batch normalization\n",
    "    # Calculate batch mean and variance\n",
    "    batch_mean1, batch_var1 = tf.nn.moments(h_conv1,[0])\n",
    "    h_conv1hat = (h_conv1-batch_mean1) / tf.sqrt(batch_var1 + 1e-3)\n",
    "    # Pooling\n",
    "    #h_pool1 = max_pool_2x2(h_conv1hat) \n",
    "    #print('h_pool1',h_pool1.shape)\n",
    "    # No_pooling\n",
    "    h_pool1 = h_conv1hat\n",
    "    print('h_pool1',h_pool1.shape)\n",
    "    \n",
    "    ## Second Convolutional Layer\n",
    "    W_conv2 = weight_variable([3, 3, 49*4, 49*4*4])\n",
    "    b_conv2 = bias_variable([49*4*4])\n",
    "    #Convolution\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "    print('h_conv2',h_conv2.shape)\n",
    "    \n",
    "    # Batch normalization\n",
    "    # Calculate batch mean and variance\n",
    "    batch_mean2, batch_var2 = tf.nn.moments(h_conv2,[0])\n",
    "    h_conv2hat = (h_conv2-batch_mean2) / tf.sqrt(batch_var2 + 1e-3)\n",
    "    \n",
    "    # Pooling\n",
    "    h_pool2 = max_pool_2x2(h_conv2hat) \n",
    "    print('h_pool2',h_pool2.shape)\n",
    "    \n",
    "    ## Third Convolutional Layer\n",
    "    W_conv3 = weight_variable([3, 3, 49*4*4, 49*4*4*2])\n",
    "    b_conv3 = bias_variable([49*4*4*2])\n",
    "    #Convolution\n",
    "    h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3)\n",
    "    print('h_conv3',h_conv3.shape)\n",
    "    \n",
    "    # Batch normalization\n",
    "    # Calculate batch mean and variance\n",
    "    batch_mean3, batch_var3 = tf.nn.moments(h_conv3,[0])\n",
    "    h_conv3hat = (h_conv3-batch_mean3) / tf.sqrt(batch_var3 + 1e-3)\n",
    "    \n",
    "    # Pooling\n",
    "    h_pool3 = max_pool_2x2(h_conv3hat) \n",
    "    print('h_pool3',h_pool3.shape)\n",
    "\n",
    "    \n",
    "    ## Third Convolutional Layer\n",
    "    W_conv4 = weight_variable([3, 3, 49*4*4*2, 49*4*4*2*2])\n",
    "    b_conv4 = bias_variable([49*4*4*2*2])\n",
    "    #Convolution\n",
    "    h_conv4 = tf.nn.relu(conv2d(h_pool3, W_conv4) + b_conv4)\n",
    "    print('h_conv4',h_conv4.shape)\n",
    "    \n",
    "    # Batch normalization\n",
    "    # Calculate batch mean and variance\n",
    "    batch_mean4, batch_var4 = tf.nn.moments(h_conv4,[0])\n",
    "    h_conv4hat = (h_conv4-batch_mean4) / tf.sqrt(batch_var4 + 1e-3)\n",
    "    \n",
    "    # Pooling\n",
    "    h_pool4 = max_pool_2x2(h_conv4hat) \n",
    "    print('h_pool4',h_pool4.shape)\n",
    "\n",
    "    ## Densely Connected Layer \n",
    "\n",
    "    # new shapes of pooled vectors\n",
    "    _, width_pooled, height_pooled, channels_pooled = h_pool4.shape\n",
    "\n",
    "    # fully-connected layer with 1024 neurons to process on the entire image\n",
    "    W_fc1 = weight_variable([int(width_pooled*height_pooled*channels_pooled), 1024])  \n",
    "    b_fc1 = bias_variable([1024])\n",
    "    \n",
    "    # Flat the output of the convolutional labels\n",
    "    h_pool4_flat = tf.reshape(h_pool4, [-1, int(width_pooled*height_pooled*channels_pooled)])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool4_flat, W_fc1) + b_fc1)\n",
    "    \n",
    "    print('h_pool4_flat',h_pool4_flat.shape)\n",
    "\n",
    "    ## Dropout (to reduce overfitting; useful when training very large neural network)\n",
    "    # We will turn on dropout during training & turn off during testing\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "    \n",
    "    ## Readout Layer\n",
    "\n",
    "    W_fc2 = weight_variable([1024, nLabel]) # [1024, 10]\n",
    "    b_fc2 = bias_variable([nLabel]) # [10]\n",
    "    \n",
    "    y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "\n",
    "    # set up for optimization (optimizer:ADAM)\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "    train_step = tf.train.AdamOptimizer(1e-3).minimize(cross_entropy)  # 1e-4\n",
    "    correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 86\n",
    "batch_size_valid = 1000\n",
    "batch_size_test = 1000\n",
    "num_steps = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy_minibatches = []\n",
    "valid_accuracy_minibatches = []\n",
    "best_validation_accuracy = 0.0\n",
    "best_validation_accuracy_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "step 0, training accuracy 0.511628\n",
      "\u001b[1m step 0, validation accuracy \u001b[0;0m 0.49\n",
      "\u001b[1m The validation accuracy has improved from the last checkpoint \u001b[0;0m\n",
      "step 5, training accuracy 0.593023\n",
      "step 10, training accuracy 0.488372\n",
      "step 15, training accuracy 0.534884\n",
      "step 20, training accuracy 0.534884\n",
      "step 25, training accuracy 0.593023\n",
      "step 30, training accuracy 0.465116\n",
      "step 35, training accuracy 0.662791\n",
      "step 40, training accuracy 0.616279\n",
      "step 45, training accuracy 0.546512\n",
      "step 50, training accuracy 0.55814\n",
      "step 55, training accuracy 0.639535\n",
      "step 60, training accuracy 0.593023\n",
      "step 65, training accuracy 0.534884\n",
      "step 70, training accuracy 0.511628\n",
      "step 75, training accuracy 0.55814\n",
      "step 80, training accuracy 0.639535\n",
      "step 85, training accuracy 0.732558\n",
      "step 90, training accuracy 0.709302\n",
      "step 95, training accuracy 0.604651\n",
      "step 100, training accuracy 0.697674\n",
      "\u001b[1m step 100, validation accuracy \u001b[0;0m 0.668\n",
      "\u001b[1m The validation accuracy has improved from the last checkpoint \u001b[0;0m\n",
      "step 105, training accuracy 0.627907\n",
      "step 110, training accuracy 0.674419\n",
      "step 115, training accuracy 0.546512\n",
      "step 120, training accuracy 0.697674\n",
      "step 125, training accuracy 0.709302\n",
      "step 130, training accuracy 0.744186\n",
      "step 135, training accuracy 0.755814\n",
      "step 140, training accuracy 0.662791\n",
      "step 145, training accuracy 0.616279\n",
      "step 150, training accuracy 0.662791\n",
      "step 155, training accuracy 0.744186\n",
      "step 160, training accuracy 0.639535\n",
      "step 165, training accuracy 0.662791\n",
      "step 170, training accuracy 0.604651\n",
      "step 175, training accuracy 0.767442\n",
      "step 180, training accuracy 0.755814\n",
      "step 185, training accuracy 0.72093\n",
      "step 190, training accuracy 0.639535\n",
      "step 195, training accuracy 0.732558\n",
      "step 200, training accuracy 0.662791\n",
      "\u001b[1m step 200, validation accuracy \u001b[0;0m 0.745\n",
      "\u001b[1m The validation accuracy has improved from the last checkpoint \u001b[0;0m\n",
      "step 205, training accuracy 0.72093\n",
      "step 210, training accuracy 0.744186\n",
      "step 215, training accuracy 0.744186\n",
      "step 220, training accuracy 0.744186\n",
      "step 225, training accuracy 0.802326\n",
      "step 230, training accuracy 0.674419\n",
      "step 235, training accuracy 0.709302\n",
      "step 240, training accuracy 0.767442\n",
      "step 245, training accuracy 0.72093\n",
      "step 250, training accuracy 0.77907\n",
      "step 255, training accuracy 0.744186\n",
      "step 260, training accuracy 0.860465\n",
      "step 265, training accuracy 0.872093\n",
      "step 270, training accuracy 0.767442\n",
      "step 275, training accuracy 0.872093\n",
      "step 280, training accuracy 0.872093\n",
      "step 285, training accuracy 0.77907\n",
      "step 290, training accuracy 0.860465\n",
      "step 295, training accuracy 0.77907\n",
      "step 300, training accuracy 0.837209\n",
      "\u001b[1m step 300, validation accuracy \u001b[0;0m 0.878\n",
      "\u001b[1m The validation accuracy has improved from the last checkpoint \u001b[0;0m\n",
      "step 305, training accuracy 0.709302\n",
      "step 310, training accuracy 0.825581\n",
      "step 315, training accuracy 0.813953\n",
      "step 320, training accuracy 0.930233\n",
      "step 325, training accuracy 0.860465\n",
      "step 330, training accuracy 0.895349\n",
      "step 335, training accuracy 0.895349\n",
      "step 340, training accuracy 0.813953\n",
      "step 345, training accuracy 0.895349\n",
      "step 350, training accuracy 0.837209\n",
      "step 355, training accuracy 0.906977\n",
      "step 360, training accuracy 0.860465\n",
      "step 365, training accuracy 0.848837\n",
      "step 370, training accuracy 0.837209\n",
      "step 375, training accuracy 0.895349\n",
      "step 380, training accuracy 0.848837\n",
      "step 385, training accuracy 0.848837\n",
      "step 390, training accuracy 0.825581\n",
      "step 395, training accuracy 0.930233\n",
      "step 400, training accuracy 0.906977\n",
      "\u001b[1m step 400, validation accuracy \u001b[0;0m 0.869\n",
      "\u001b[1m The validation accuracy DID NOT improved from the last checkpoint \u001b[0;0m\n",
      "step 405, training accuracy 0.906977\n",
      "step 410, training accuracy 0.883721\n",
      "step 415, training accuracy 0.906977\n",
      "step 420, training accuracy 0.872093\n",
      "step 425, training accuracy 0.790698\n",
      "step 430, training accuracy 0.918605\n",
      "step 435, training accuracy 0.906977\n",
      "step 440, training accuracy 0.837209\n",
      "step 445, training accuracy 0.906977\n",
      "step 450, training accuracy 0.872093\n",
      "step 455, training accuracy 0.930233\n",
      "step 460, training accuracy 0.918605\n",
      "step 465, training accuracy 0.895349\n",
      "step 470, training accuracy 0.965116\n",
      "step 475, training accuracy 0.906977\n",
      "step 480, training accuracy 0.953488\n",
      "step 485, training accuracy 0.860465\n",
      "step 490, training accuracy 0.906977\n",
      "step 495, training accuracy 0.906977\n",
      "step 500, training accuracy 0.883721\n",
      "\u001b[1m step 500, validation accuracy \u001b[0;0m 0.93\n",
      "\u001b[1m The validation accuracy has improved from the last checkpoint \u001b[0;0m\n",
      "step 505, training accuracy 0.895349\n",
      "step 510, training accuracy 0.930233\n",
      "step 515, training accuracy 0.965116\n",
      "step 520, training accuracy 0.895349\n",
      "step 525, training accuracy 0.895349\n",
      "step 530, training accuracy 0.953488\n",
      "step 535, training accuracy 0.965116\n",
      "step 540, training accuracy 0.906977\n",
      "step 545, training accuracy 0.918605\n",
      "step 550, training accuracy 0.918605\n",
      "step 555, training accuracy 0.883721\n",
      "step 560, training accuracy 0.918605\n",
      "step 565, training accuracy 0.930233\n",
      "step 570, training accuracy 0.906977\n",
      "step 575, training accuracy 0.895349\n",
      "step 580, training accuracy 0.930233\n",
      "step 585, training accuracy 0.918605\n",
      "step 590, training accuracy 0.918605\n",
      "step 595, training accuracy 0.953488\n",
      "step 600, training accuracy 0.988372\n",
      "\u001b[1m step 600, validation accuracy \u001b[0;0m 0.929\n",
      "\u001b[1m The validation accuracy DID NOT improved from the last checkpoint \u001b[0;0m\n",
      "step 605, training accuracy 0.965116\n",
      "step 610, training accuracy 0.930233\n",
      "step 615, training accuracy 0.953488\n",
      "step 620, training accuracy 0.883721\n",
      "step 625, training accuracy 0.953488\n",
      "step 630, training accuracy 0.930233\n",
      "step 635, training accuracy 0.918605\n",
      "step 640, training accuracy 0.918605\n",
      "step 645, training accuracy 0.930233\n",
      "step 650, training accuracy 0.918605\n",
      "step 655, training accuracy 0.953488\n",
      "step 660, training accuracy 0.94186\n",
      "step 665, training accuracy 0.930233\n",
      "step 670, training accuracy 0.94186\n",
      "step 675, training accuracy 0.953488\n",
      "step 680, training accuracy 0.918605\n",
      "step 685, training accuracy 0.895349\n",
      "step 690, training accuracy 0.906977\n",
      "step 695, training accuracy 0.848837\n",
      "step 700, training accuracy 0.953488\n",
      "\u001b[1m step 700, validation accuracy \u001b[0;0m 0.928\n",
      "\u001b[1m The validation accuracy DID NOT improved from the last checkpoint \u001b[0;0m\n",
      "step 705, training accuracy 0.930233\n",
      "step 710, training accuracy 0.848837\n",
      "step 715, training accuracy 0.94186\n",
      "step 720, training accuracy 0.906977\n",
      "step 725, training accuracy 0.930233\n",
      "step 730, training accuracy 0.965116\n",
      "step 735, training accuracy 0.918605\n",
      "step 740, training accuracy 0.976744\n",
      "step 745, training accuracy 0.906977\n",
      "step 750, training accuracy 0.965116\n",
      "step 755, training accuracy 0.94186\n",
      "step 760, training accuracy 0.953488\n",
      "step 765, training accuracy 0.953488\n",
      "step 770, training accuracy 0.895349\n",
      "step 775, training accuracy 0.953488\n",
      "step 780, training accuracy 0.918605\n",
      "step 785, training accuracy 0.953488\n",
      "step 790, training accuracy 0.976744\n",
      "step 795, training accuracy 0.953488\n",
      "step 800, training accuracy 0.94186\n",
      "\u001b[1m step 800, validation accuracy \u001b[0;0m 0.933\n",
      "\u001b[1m The validation accuracy has improved from the last checkpoint \u001b[0;0m\n",
      "step 805, training accuracy 0.953488\n",
      "step 810, training accuracy 0.930233\n",
      "step 815, training accuracy 0.953488\n",
      "step 820, training accuracy 0.906977\n",
      "step 825, training accuracy 0.930233\n",
      "step 830, training accuracy 0.94186\n",
      "step 835, training accuracy 1\n",
      "step 840, training accuracy 0.976744\n",
      "step 845, training accuracy 0.837209\n",
      "step 850, training accuracy 0.94186\n",
      "step 855, training accuracy 0.94186\n",
      "step 860, training accuracy 0.94186\n",
      "step 865, training accuracy 0.953488\n",
      "step 870, training accuracy 0.965116\n",
      "step 875, training accuracy 0.965116\n",
      "step 880, training accuracy 0.94186\n",
      "step 885, training accuracy 0.953488\n",
      "step 890, training accuracy 0.872093\n",
      "step 895, training accuracy 0.953488\n",
      "step 900, training accuracy 0.94186\n",
      "\u001b[1m step 900, validation accuracy \u001b[0;0m 0.957\n",
      "\u001b[1m The validation accuracy has improved from the last checkpoint \u001b[0;0m\n",
      "step 905, training accuracy 0.848837\n",
      "step 910, training accuracy 0.895349\n",
      "step 915, training accuracy 0.94186\n",
      "step 920, training accuracy 0.965116\n",
      "step 925, training accuracy 0.976744\n",
      "step 930, training accuracy 0.930233\n",
      "step 935, training accuracy 0.930233\n",
      "step 940, training accuracy 0.94186\n",
      "step 945, training accuracy 0.976744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 950, training accuracy 0.930233\n",
      "step 955, training accuracy 0.94186\n",
      "step 960, training accuracy 0.918605\n",
      "step 965, training accuracy 0.94186\n",
      "step 970, training accuracy 0.965116\n",
      "step 975, training accuracy 0.976744\n",
      "step 980, training accuracy 0.906977\n",
      "step 985, training accuracy 0.953488\n",
      "step 990, training accuracy 0.965116\n",
      "step 995, training accuracy 0.965116\n",
      "step 1000, training accuracy 0.976744\n",
      "\u001b[1m step 1000, validation accuracy \u001b[0;0m 0.956\n",
      "\u001b[1m The validation accuracy DID NOT improved from the last checkpoint \u001b[0;0m\n",
      "step 1005, training accuracy 0.94186\n",
      "step 1010, training accuracy 0.976744\n",
      "step 1015, training accuracy 0.930233\n",
      "step 1020, training accuracy 0.94186\n",
      "step 1025, training accuracy 0.94186\n",
      "step 1030, training accuracy 0.94186\n",
      "step 1035, training accuracy 0.965116\n",
      "step 1040, training accuracy 0.918605\n",
      "step 1045, training accuracy 0.965116\n",
      "step 1050, training accuracy 0.930233\n",
      "step 1055, training accuracy 0.953488\n",
      "step 1060, training accuracy 0.988372\n",
      "step 1065, training accuracy 0.94186\n",
      "step 1070, training accuracy 0.965116\n",
      "step 1075, training accuracy 0.94186\n",
      "step 1080, training accuracy 0.953488\n",
      "step 1085, training accuracy 0.918605\n",
      "step 1090, training accuracy 0.965116\n",
      "step 1095, training accuracy 0.918605\n",
      "step 1100, training accuracy 0.918605\n",
      "\u001b[1m step 1100, validation accuracy \u001b[0;0m 0.932\n",
      "\u001b[1m The validation accuracy DID NOT improved from the last checkpoint \u001b[0;0m\n",
      "step 1105, training accuracy 0.965116\n",
      "step 1110, training accuracy 0.965116\n",
      "step 1115, training accuracy 0.930233\n",
      "step 1120, training accuracy 0.953488\n",
      "step 1125, training accuracy 0.976744\n",
      "step 1130, training accuracy 0.965116\n",
      "step 1135, training accuracy 0.930233\n",
      "step 1140, training accuracy 0.94186\n",
      "step 1145, training accuracy 0.953488\n",
      "step 1150, training accuracy 0.965116\n",
      "step 1155, training accuracy 0.988372\n",
      "step 1160, training accuracy 0.883721\n",
      "step 1165, training accuracy 0.976744\n",
      "step 1170, training accuracy 0.953488\n",
      "step 1175, training accuracy 0.918605\n",
      "step 1180, training accuracy 0.930233\n",
      "step 1185, training accuracy 0.906977\n",
      "step 1190, training accuracy 0.906977\n",
      "step 1195, training accuracy 0.953488\n",
      "step 1200, training accuracy 0.94186\n",
      "\u001b[1m step 1200, validation accuracy \u001b[0;0m 0.946\n",
      "\u001b[1m The validation accuracy DID NOT improved from the last checkpoint \u001b[0;0m\n",
      "step 1205, training accuracy 0.94186\n",
      "step 1210, training accuracy 0.895349\n",
      "step 1215, training accuracy 0.953488\n",
      "step 1220, training accuracy 0.965116\n",
      "step 1225, training accuracy 0.953488\n",
      "step 1230, training accuracy 0.965116\n",
      "step 1235, training accuracy 0.953488\n",
      "step 1240, training accuracy 0.953488\n",
      "step 1245, training accuracy 0.965116\n",
      "step 1250, training accuracy 0.883721\n",
      "step 1255, training accuracy 0.976744\n",
      "step 1260, training accuracy 0.976744\n",
      "step 1265, training accuracy 0.953488\n",
      "step 1270, training accuracy 0.953488\n",
      "step 1275, training accuracy 0.918605\n",
      "step 1280, training accuracy 0.965116\n",
      "step 1285, training accuracy 0.94186\n",
      "step 1290, training accuracy 0.94186\n",
      "step 1295, training accuracy 0.930233\n",
      "step 1300, training accuracy 0.953488\n",
      "\u001b[1m step 1300, validation accuracy \u001b[0;0m 0.957\n",
      "\u001b[1m The validation accuracy DID NOT improved from the last checkpoint \u001b[0;0m\n",
      "step 1305, training accuracy 0.965116\n",
      "step 1310, training accuracy 0.930233\n",
      "step 1315, training accuracy 0.953488\n",
      "step 1320, training accuracy 0.94186\n",
      "step 1325, training accuracy 0.94186\n",
      "step 1330, training accuracy 0.965116\n",
      "step 1335, training accuracy 0.965116\n",
      "step 1340, training accuracy 0.94186\n",
      "step 1345, training accuracy 0.953488\n",
      "step 1350, training accuracy 0.953488\n",
      "step 1355, training accuracy 0.976744\n",
      "step 1360, training accuracy 0.930233\n",
      "step 1365, training accuracy 0.918605\n",
      "step 1370, training accuracy 0.930233\n",
      "step 1375, training accuracy 0.976744\n",
      "step 1380, training accuracy 0.976744\n",
      "step 1385, training accuracy 0.883721\n",
      "step 1390, training accuracy 0.965116\n",
      "step 1395, training accuracy 0.953488\n",
      "step 1400, training accuracy 0.965116\n",
      "\u001b[1m step 1400, validation accuracy \u001b[0;0m 0.948\n",
      "\u001b[1m The validation accuracy DID NOT improved from the last checkpoint \u001b[0;0m\n",
      "step 1405, training accuracy 0.906977\n",
      "step 1410, training accuracy 0.953488\n",
      "step 1415, training accuracy 0.94186\n",
      "step 1420, training accuracy 0.94186\n",
      "step 1425, training accuracy 0.94186\n",
      "step 1430, training accuracy 0.906977\n",
      "step 1435, training accuracy 0.965116\n",
      "step 1440, training accuracy 0.930233\n",
      "step 1445, training accuracy 0.918605\n",
      "step 1450, training accuracy 0.918605\n",
      "step 1455, training accuracy 0.965116\n",
      "step 1460, training accuracy 0.965116\n",
      "step 1465, training accuracy 0.953488\n",
      "step 1470, training accuracy 0.953488\n",
      "step 1475, training accuracy 0.953488\n",
      "step 1480, training accuracy 0.94186\n",
      "step 1485, training accuracy 0.918605\n",
      "step 1490, training accuracy 0.965116\n",
      "step 1495, training accuracy 0.988372\n",
      "step 1500, training accuracy 0.965116\n",
      "\u001b[1m step 1500, validation accuracy \u001b[0;0m 0.944\n",
      "\u001b[1m The validation accuracy DID NOT improved from the last checkpoint \u001b[0;0m\n",
      "step 1505, training accuracy 0.930233\n",
      "step 1510, training accuracy 0.965116\n",
      "step 1515, training accuracy 1\n",
      "step 1520, training accuracy 0.883721\n",
      "step 1525, training accuracy 0.953488\n",
      "step 1530, training accuracy 0.976744\n",
      "step 1535, training accuracy 0.965116\n",
      "step 1540, training accuracy 0.94186\n",
      "step 1545, training accuracy 0.965116\n",
      "step 1550, training accuracy 0.94186\n",
      "step 1555, training accuracy 0.930233\n",
      "step 1560, training accuracy 0.918605\n",
      "step 1565, training accuracy 0.930233\n",
      "step 1570, training accuracy 0.953488\n",
      "step 1575, training accuracy 0.965116\n",
      "step 1580, training accuracy 0.906977\n",
      "step 1585, training accuracy 0.965116\n",
      "step 1590, training accuracy 0.918605\n",
      "step 1595, training accuracy 0.988372\n",
      "step 1600, training accuracy 0.953488\n",
      "\u001b[1m step 1600, validation accuracy \u001b[0;0m 0.97\n",
      "\u001b[1m The validation accuracy has improved from the last checkpoint \u001b[0;0m\n",
      "step 1605, training accuracy 0.965116\n",
      "step 1610, training accuracy 0.953488\n",
      "step 1615, training accuracy 0.953488\n",
      "step 1620, training accuracy 0.94186\n",
      "step 1625, training accuracy 0.988372\n",
      "step 1630, training accuracy 0.930233\n",
      "step 1635, training accuracy 0.94186\n",
      "step 1640, training accuracy 0.930233\n",
      "step 1645, training accuracy 0.953488\n",
      "step 1650, training accuracy 1\n",
      "step 1655, training accuracy 0.930233\n",
      "step 1660, training accuracy 0.988372\n",
      "step 1665, training accuracy 0.976744\n",
      "step 1670, training accuracy 0.965116\n",
      "step 1675, training accuracy 0.953488\n",
      "step 1680, training accuracy 0.965116\n",
      "step 1685, training accuracy 0.976744\n",
      "step 1690, training accuracy 0.953488\n",
      "step 1695, training accuracy 0.930233\n",
      "step 1700, training accuracy 0.953488\n",
      "\u001b[1m step 1700, validation accuracy \u001b[0;0m 0.962\n",
      "\u001b[1m The validation accuracy DID NOT improved from the last checkpoint \u001b[0;0m\n",
      "step 1705, training accuracy 0.965116\n",
      "step 1710, training accuracy 0.965116\n",
      "step 1715, training accuracy 0.895349\n",
      "step 1720, training accuracy 0.918605\n",
      "step 1725, training accuracy 0.953488\n",
      "step 1730, training accuracy 0.976744\n",
      "step 1735, training accuracy 1\n",
      "step 1740, training accuracy 0.965116\n",
      "step 1745, training accuracy 0.953488\n",
      "step 1750, training accuracy 0.953488\n",
      "step 1755, training accuracy 0.965116\n",
      "step 1760, training accuracy 0.94186\n",
      "step 1765, training accuracy 0.953488\n",
      "step 1770, training accuracy 0.965116\n",
      "step 1775, training accuracy 0.918605\n",
      "step 1780, training accuracy 0.976744\n",
      "step 1785, training accuracy 0.988372\n",
      "step 1790, training accuracy 0.94186\n",
      "step 1795, training accuracy 0.953488\n",
      "step 1800, training accuracy 0.953488\n",
      "\u001b[1m step 1800, validation accuracy \u001b[0;0m 0.945\n",
      "\u001b[1m The validation accuracy DID NOT improved from the last checkpoint \u001b[0;0m\n",
      "step 1805, training accuracy 0.930233\n",
      "step 1810, training accuracy 0.976744\n",
      "step 1815, training accuracy 0.976744\n",
      "step 1820, training accuracy 0.930233\n",
      "step 1825, training accuracy 0.953488\n",
      "step 1830, training accuracy 0.953488\n",
      "step 1835, training accuracy 0.953488\n",
      "step 1840, training accuracy 0.94186\n",
      "step 1845, training accuracy 0.976744\n",
      "step 1850, training accuracy 0.953488\n",
      "step 1855, training accuracy 0.976744\n",
      "step 1860, training accuracy 0.930233\n",
      "step 1865, training accuracy 0.976744\n",
      "step 1870, training accuracy 0.976744\n",
      "step 1875, training accuracy 0.976744\n",
      "step 1880, training accuracy 0.953488\n",
      "step 1885, training accuracy 0.918605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1890, training accuracy 0.976744\n",
      "step 1895, training accuracy 0.988372\n",
      "step 1900, training accuracy 0.988372\n",
      "\u001b[1m step 1900, validation accuracy \u001b[0;0m 0.956\n",
      "\u001b[1m The validation accuracy DID NOT improved from the last checkpoint \u001b[0;0m\n",
      "step 1905, training accuracy 0.94186\n",
      "step 1910, training accuracy 0.965116\n",
      "step 1915, training accuracy 0.965116\n",
      "step 1920, training accuracy 0.988372\n",
      "step 1925, training accuracy 0.965116\n",
      "step 1930, training accuracy 0.965116\n",
      "step 1935, training accuracy 0.94186\n",
      "step 1940, training accuracy 0.930233\n",
      "step 1945, training accuracy 0.918605\n",
      "step 1950, training accuracy 0.953488\n",
      "step 1955, training accuracy 0.988372\n",
      "step 1960, training accuracy 0.953488\n",
      "step 1965, training accuracy 0.953488\n",
      "step 1970, training accuracy 0.953488\n",
      "step 1975, training accuracy 0.965116\n",
      "step 1980, training accuracy 0.976744\n",
      "step 1985, training accuracy 0.930233\n",
      "step 1990, training accuracy 0.976744\n",
      "step 1995, training accuracy 0.965116\n",
      "step 2000, training accuracy 0.953488\n",
      "\u001b[1m step 2000, validation accuracy \u001b[0;0m 0.96\n",
      "\u001b[1m The validation accuracy DID NOT improved from the last checkpoint \u001b[0;0m\n",
      "step 2005, training accuracy 0.988372\n",
      "step 2010, training accuracy 0.930233\n",
      "step 2015, training accuracy 0.976744\n",
      "step 2020, training accuracy 0.953488\n",
      "step 2025, training accuracy 0.94186\n",
      "step 2030, training accuracy 0.906977\n",
      "step 2035, training accuracy 0.94186\n",
      "step 2040, training accuracy 0.953488\n",
      "step 2045, training accuracy 0.930233\n",
      "step 2050, training accuracy 0.94186\n",
      "step 2055, training accuracy 0.976744\n",
      "step 2060, training accuracy 0.930233\n",
      "step 2065, training accuracy 0.953488\n",
      "step 2070, training accuracy 0.976744\n",
      "step 2075, training accuracy 1\n",
      "step 2080, training accuracy 0.988372\n",
      "step 2085, training accuracy 0.976744\n",
      "step 2090, training accuracy 0.953488\n",
      "step 2095, training accuracy 0.965116\n",
      "step 2100, training accuracy 0.976744\n",
      "\u001b[1m step 2100, validation accuracy \u001b[0;0m 0.959\n",
      "\u001b[1m The validation accuracy DID NOT improved from the last checkpoint \u001b[0;0m\n",
      "step 2105, training accuracy 0.953488\n",
      "step 2110, training accuracy 0.953488\n",
      "step 2115, training accuracy 0.965116\n",
      "step 2120, training accuracy 0.94186\n",
      "step 2125, training accuracy 0.965116\n",
      "step 2130, training accuracy 0.965116\n",
      "step 2135, training accuracy 1\n",
      "step 2140, training accuracy 0.988372\n",
      "step 2145, training accuracy 0.94186\n",
      "step 2150, training accuracy 0.930233\n",
      "step 2155, training accuracy 0.930233\n",
      "step 2160, training accuracy 0.94186\n",
      "step 2165, training accuracy 0.965116\n",
      "step 2170, training accuracy 0.988372\n",
      "step 2175, training accuracy 0.965116\n",
      "step 2180, training accuracy 0.94186\n",
      "step 2185, training accuracy 0.976744\n",
      "step 2190, training accuracy 0.988372\n",
      "step 2195, training accuracy 0.918605\n",
      "step 2200, training accuracy 0.930233\n",
      "\u001b[1m step 2200, validation accuracy \u001b[0;0m 0.956\n",
      "\u001b[1m The validation accuracy DID NOT improved from the last checkpoint \u001b[0;0m\n",
      "step 2205, training accuracy 0.918605\n",
      "step 2210, training accuracy 0.953488\n",
      "step 2215, training accuracy 0.976744\n",
      "step 2220, training accuracy 0.953488\n",
      "step 2225, training accuracy 0.965116\n",
      "step 2230, training accuracy 0.953488\n",
      "step 2235, training accuracy 0.953488\n",
      "step 2240, training accuracy 0.930233\n",
      "step 2245, training accuracy 0.930233\n",
      "step 2250, training accuracy 0.965116\n",
      "step 2255, training accuracy 0.94186\n",
      "step 2260, training accuracy 0.976744\n",
      "step 2265, training accuracy 0.94186\n",
      "step 2270, training accuracy 0.976744\n",
      "step 2275, training accuracy 0.965116\n",
      "step 2280, training accuracy 0.976744\n",
      "step 2285, training accuracy 0.953488\n",
      "step 2290, training accuracy 0.930233\n",
      "step 2295, training accuracy 0.965116\n",
      "step 2300, training accuracy 0.965116\n",
      "\u001b[1m step 2300, validation accuracy \u001b[0;0m 0.969\n",
      "\u001b[1m The validation accuracy DID NOT improved from the last checkpoint \u001b[0;0m\n",
      "step 2305, training accuracy 0.988372\n",
      "step 2310, training accuracy 0.976744\n",
      "step 2315, training accuracy 0.976744\n",
      "step 2320, training accuracy 0.976744\n",
      "step 2325, training accuracy 0.976744\n",
      "step 2330, training accuracy 0.930233\n",
      "step 2335, training accuracy 0.965116\n",
      "step 2340, training accuracy 0.976744\n",
      "step 2345, training accuracy 0.918605\n",
      "step 2350, training accuracy 0.976744\n",
      "step 2355, training accuracy 0.965116\n",
      "step 2360, training accuracy 1\n",
      "step 2365, training accuracy 0.953488\n",
      "step 2370, training accuracy 0.965116\n",
      "step 2375, training accuracy 0.953488\n",
      "step 2380, training accuracy 0.94186\n",
      "step 2385, training accuracy 0.965116\n",
      "step 2390, training accuracy 0.906977\n",
      "step 2395, training accuracy 0.953488\n",
      "step 2400, training accuracy 0.94186\n",
      "\u001b[1m step 2400, validation accuracy \u001b[0;0m 0.942\n",
      "\u001b[1m The validation accuracy DID NOT improved from the last checkpoint \u001b[0;0m\n",
      "step 2405, training accuracy 0.988372\n",
      "step 2410, training accuracy 0.965116\n",
      "step 2415, training accuracy 0.965116\n",
      "step 2420, training accuracy 0.976744\n",
      "step 2425, training accuracy 0.883721\n",
      "step 2430, training accuracy 0.953488\n",
      "step 2435, training accuracy 0.976744\n",
      "step 2440, training accuracy 0.953488\n",
      "step 2445, training accuracy 0.895349\n",
      "step 2450, training accuracy 0.965116\n",
      "step 2455, training accuracy 0.94186\n",
      "step 2460, training accuracy 0.976744\n",
      "step 2465, training accuracy 0.918605\n",
      "step 2470, training accuracy 0.930233\n",
      "step 2475, training accuracy 0.965116\n",
      "step 2480, training accuracy 0.988372\n",
      "step 2485, training accuracy 0.895349\n",
      "step 2490, training accuracy 0.965116\n",
      "step 2495, training accuracy 0.953488\n",
      "step 2500, training accuracy 0.976744\n",
      "\u001b[1m step 2500, validation accuracy \u001b[0;0m 0.958\n",
      "\u001b[1m The validation accuracy DID NOT improved from the last checkpoint \u001b[0;0m\n",
      "step 2505, training accuracy 0.906977\n",
      "step 2510, training accuracy 0.988372\n",
      "step 2515, training accuracy 0.976744\n",
      "step 2520, training accuracy 0.953488\n",
      "step 2525, training accuracy 0.94186\n",
      "step 2530, training accuracy 0.94186\n",
      "step 2535, training accuracy 0.953488\n",
      "step 2540, training accuracy 0.965116\n",
      "step 2545, training accuracy 0.976744\n",
      "step 2550, training accuracy 0.976744\n",
      "step 2555, training accuracy 0.965116\n",
      "step 2560, training accuracy 0.918605\n",
      "step 2565, training accuracy 0.976744\n",
      "step 2570, training accuracy 0.976744\n",
      "step 2575, training accuracy 0.988372\n",
      "step 2580, training accuracy 0.976744\n",
      "step 2585, training accuracy 1\n",
      "step 2590, training accuracy 0.94186\n",
      "step 2595, training accuracy 0.976744\n",
      "step 2600, training accuracy 0.965116\n",
      "\u001b[1m step 2600, validation accuracy \u001b[0;0m 0.967\n",
      "\u001b[1m The validation accuracy DID NOT improved from the last checkpoint \u001b[0;0m\n",
      "step 2605, training accuracy 0.965116\n",
      "step 2610, training accuracy 0.988372\n",
      "step 2615, training accuracy 0.953488\n",
      "step 2620, training accuracy 0.976744\n",
      "step 2625, training accuracy 0.988372\n",
      "step 2630, training accuracy 0.965116\n",
      "step 2635, training accuracy 0.918605\n",
      "step 2640, training accuracy 0.976744\n",
      "step 2645, training accuracy 0.953488\n",
      "step 2650, training accuracy 0.953488\n",
      "step 2655, training accuracy 0.965116\n",
      "step 2660, training accuracy 0.965116\n",
      "step 2665, training accuracy 0.976744\n",
      "step 2670, training accuracy 0.918605\n",
      "step 2675, training accuracy 0.988372\n",
      "step 2680, training accuracy 0.988372\n",
      "step 2685, training accuracy 0.976744\n",
      "step 2690, training accuracy 0.94186\n",
      "step 2695, training accuracy 0.965116\n",
      "step 2700, training accuracy 0.930233\n",
      "\u001b[1m step 2700, validation accuracy \u001b[0;0m 0.953\n",
      "\u001b[1m The validation accuracy DID NOT improved from the last checkpoint \u001b[0;0m\n",
      "step 2705, training accuracy 0.965116\n",
      "step 2710, training accuracy 0.976744\n",
      "step 2715, training accuracy 0.953488\n",
      "step 2720, training accuracy 0.965116\n",
      "step 2725, training accuracy 0.965116\n",
      "step 2730, training accuracy 0.988372\n",
      "step 2735, training accuracy 0.988372\n",
      "step 2740, training accuracy 0.930233\n",
      "step 2745, training accuracy 0.988372\n",
      "step 2750, training accuracy 0.953488\n",
      "step 2755, training accuracy 0.895349\n",
      "step 2760, training accuracy 0.976744\n",
      "step 2765, training accuracy 0.906977\n",
      "step 2770, training accuracy 0.883721\n",
      "step 2775, training accuracy 0.965116\n",
      "step 2780, training accuracy 0.918605\n",
      "step 2785, training accuracy 0.94186\n",
      "step 2790, training accuracy 0.906977\n",
      "step 2795, training accuracy 0.976744\n",
      "step 2800, training accuracy 0.965116\n",
      "\u001b[1m step 2800, validation accuracy \u001b[0;0m 0.958\n",
      "\u001b[1m The validation accuracy DID NOT improved from the last checkpoint \u001b[0;0m\n",
      "step 2805, training accuracy 0.976744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2810, training accuracy 0.976744\n",
      "step 2815, training accuracy 0.94186\n",
      "step 2820, training accuracy 0.965116\n",
      "step 2825, training accuracy 0.965116\n",
      "step 2830, training accuracy 0.965116\n",
      "step 2835, training accuracy 0.953488\n",
      "step 2840, training accuracy 0.976744\n",
      "step 2845, training accuracy 0.976744\n",
      "step 2850, training accuracy 0.988372\n",
      "step 2855, training accuracy 0.965116\n",
      "step 2860, training accuracy 0.976744\n",
      "step 2865, training accuracy 0.965116\n",
      "step 2870, training accuracy 0.988372\n",
      "step 2875, training accuracy 0.976744\n",
      "step 2880, training accuracy 0.953488\n",
      "step 2885, training accuracy 0.953488\n",
      "step 2890, training accuracy 0.965116\n",
      "step 2895, training accuracy 0.988372\n",
      "step 2900, training accuracy 0.976744\n",
      "\u001b[1m step 2900, validation accuracy \u001b[0;0m 0.969\n",
      "\u001b[1m The validation accuracy DID NOT improved from the last checkpoint \u001b[0;0m\n",
      "step 2905, training accuracy 0.94186\n",
      "step 2910, training accuracy 0.965116\n",
      "step 2915, training accuracy 0.965116\n",
      "step 2920, training accuracy 0.965116\n",
      "step 2925, training accuracy 0.976744\n",
      "step 2930, training accuracy 0.976744\n",
      "step 2935, training accuracy 0.976744\n",
      "step 2940, training accuracy 0.918605\n",
      "step 2945, training accuracy 1\n",
      "step 2950, training accuracy 0.94186\n",
      "step 2955, training accuracy 0.976744\n",
      "step 2960, training accuracy 1\n",
      "step 2965, training accuracy 0.94186\n",
      "step 2970, training accuracy 0.953488\n",
      "step 2975, training accuracy 0.918605\n",
      "step 2980, training accuracy 0.976744\n",
      "step 2985, training accuracy 0.965116\n",
      "step 2990, training accuracy 0.976744\n",
      "step 2995, training accuracy 0.988372\n",
      "step 3000, training accuracy 0.965116\n",
      "\u001b[1m step 3000, validation accuracy \u001b[0;0m 0.981\n",
      "\u001b[1m The validation accuracy has improved from the last checkpoint \u001b[0;0m\n",
      "step 3005, training accuracy 0.953488\n",
      "step 3010, training accuracy 0.976744\n",
      "step 3015, training accuracy 0.965116\n",
      "step 3020, training accuracy 0.988372\n",
      "step 3025, training accuracy 0.976744\n",
      "step 3030, training accuracy 0.976744\n",
      "step 3035, training accuracy 0.953488\n",
      "step 3040, training accuracy 0.930233\n",
      "step 3045, training accuracy 0.953488\n",
      "step 3050, training accuracy 0.94186\n",
      "step 3055, training accuracy 0.906977\n",
      "step 3060, training accuracy 0.965116\n",
      "step 3065, training accuracy 0.988372\n",
      "step 3070, training accuracy 0.988372\n",
      "step 3075, training accuracy 0.976744\n",
      "step 3080, training accuracy 0.988372\n",
      "step 3085, training accuracy 0.953488\n",
      "step 3090, training accuracy 0.976744\n",
      "step 3095, training accuracy 0.988372\n",
      "step 3100, training accuracy 0.965116\n",
      "\u001b[1m step 3100, validation accuracy \u001b[0;0m 0.974\n",
      "\u001b[1m The validation accuracy DID NOT improved from the last checkpoint \u001b[0;0m\n",
      "step 3105, training accuracy 0.988372\n",
      "step 3110, training accuracy 0.965116\n",
      "step 3115, training accuracy 0.965116\n",
      "step 3120, training accuracy 0.965116\n",
      "step 3125, training accuracy 0.965116\n",
      "step 3130, training accuracy 0.988372\n",
      "step 3135, training accuracy 0.976744\n",
      "step 3140, training accuracy 0.965116\n",
      "step 3145, training accuracy 0.976744\n",
      "step 3150, training accuracy 0.930233\n",
      "step 3155, training accuracy 1\n",
      "step 3160, training accuracy 0.94186\n",
      "step 3165, training accuracy 0.965116\n",
      "step 3170, training accuracy 0.976744\n",
      "step 3175, training accuracy 0.953488\n",
      "step 3180, training accuracy 0.965116\n",
      "step 3185, training accuracy 0.976744\n",
      "step 3190, training accuracy 0.953488\n",
      "step 3195, training accuracy 0.988372\n",
      "step 3200, training accuracy 1\n",
      "\u001b[1m step 3200, validation accuracy \u001b[0;0m 0.969\n",
      "\u001b[1m The validation accuracy DID NOT improved from the last checkpoint \u001b[0;0m\n",
      "step 3205, training accuracy 1\n",
      "step 3210, training accuracy 0.976744\n",
      "step 3215, training accuracy 0.965116\n",
      "step 3220, training accuracy 0.965116\n",
      "step 3225, training accuracy 0.976744\n",
      "step 3230, training accuracy 0.988372\n",
      "step 3235, training accuracy 0.918605\n",
      "step 3240, training accuracy 0.976744\n",
      "step 3245, training accuracy 0.976744\n",
      "step 3250, training accuracy 0.965116\n",
      "step 3255, training accuracy 1\n",
      "step 3260, training accuracy 0.976744\n",
      "step 3265, training accuracy 0.988372\n",
      "step 3270, training accuracy 0.965116\n",
      "step 3275, training accuracy 0.965116\n",
      "step 3280, training accuracy 1\n",
      "step 3285, training accuracy 0.965116\n",
      "step 3290, training accuracy 0.988372\n",
      "step 3295, training accuracy 0.988372\n",
      "step 3300, training accuracy 0.988372\n",
      "\u001b[1m step 3300, validation accuracy \u001b[0;0m 0.979\n",
      "\u001b[1m The validation accuracy DID NOT improved from the last checkpoint \u001b[0;0m\n",
      "step 3305, training accuracy 0.988372\n",
      "step 3310, training accuracy 0.94186\n",
      "step 3315, training accuracy 0.976744\n",
      "step 3320, training accuracy 0.965116\n",
      "step 3325, training accuracy 0.976744\n",
      "step 3330, training accuracy 0.976744\n",
      "step 3335, training accuracy 0.988372\n",
      "step 3340, training accuracy 0.976744\n",
      "step 3345, training accuracy 0.976744\n",
      "step 3350, training accuracy 1\n",
      "step 3355, training accuracy 0.953488\n",
      "step 3360, training accuracy 0.988372\n",
      "step 3365, training accuracy 0.976744\n",
      "step 3370, training accuracy 0.930233\n",
      "step 3375, training accuracy 0.965116\n",
      "step 3380, training accuracy 0.965116\n",
      "step 3385, training accuracy 1\n",
      "step 3390, training accuracy 1\n",
      "step 3395, training accuracy 0.965116\n",
      "step 3400, training accuracy 0.965116\n",
      "\u001b[1m step 3400, validation accuracy \u001b[0;0m 0.973\n",
      "\u001b[1m The validation accuracy DID NOT improved from the last checkpoint \u001b[0;0m\n",
      "step 3405, training accuracy 0.965116\n",
      "step 3410, training accuracy 0.988372\n",
      "step 3415, training accuracy 0.930233\n",
      "step 3420, training accuracy 0.988372\n",
      "step 3425, training accuracy 0.976744\n",
      "step 3430, training accuracy 0.976744\n",
      "step 3435, training accuracy 1\n",
      "step 3440, training accuracy 0.988372\n",
      "step 3445, training accuracy 0.965116\n",
      "step 3450, training accuracy 0.976744\n",
      "step 3455, training accuracy 0.988372\n",
      "step 3460, training accuracy 0.988372\n",
      "step 3465, training accuracy 0.976744\n",
      "step 3470, training accuracy 0.988372\n",
      "step 3475, training accuracy 0.976744\n",
      "step 3480, training accuracy 0.965116\n",
      "step 3485, training accuracy 0.988372\n",
      "step 3490, training accuracy 0.953488\n",
      "step 3495, training accuracy 0.988372\n",
      "step 3500, training accuracy 0.976744\n",
      "\u001b[1m step 3500, validation accuracy \u001b[0;0m 0.965\n",
      "\u001b[1m The validation accuracy DID NOT improved from the last checkpoint \u001b[0;0m\n",
      "step 3505, training accuracy 0.965116\n",
      "step 3510, training accuracy 0.965116\n",
      "step 3515, training accuracy 0.976744\n",
      "step 3520, training accuracy 1\n",
      "step 3525, training accuracy 0.988372\n",
      "step 3530, training accuracy 0.953488\n",
      "step 3535, training accuracy 0.988372\n",
      "step 3540, training accuracy 0.988372\n",
      "step 3545, training accuracy 0.988372\n",
      "step 3550, training accuracy 0.953488\n",
      "step 3555, training accuracy 0.988372\n",
      "step 3560, training accuracy 0.988372\n",
      "step 3565, training accuracy 0.965116\n",
      "step 3570, training accuracy 0.965116\n",
      "step 3575, training accuracy 0.976744\n",
      "step 3580, training accuracy 0.94186\n",
      "step 3585, training accuracy 0.976744\n",
      "step 3590, training accuracy 0.976744\n",
      "step 3595, training accuracy 0.988372\n",
      "step 3600, training accuracy 0.988372\n",
      "\u001b[1m step 3600, validation accuracy \u001b[0;0m 0.97\n",
      "\u001b[1m The validation accuracy DID NOT improved from the last checkpoint \u001b[0;0m\n",
      "step 3605, training accuracy 0.976744\n",
      "step 3610, training accuracy 0.965116\n",
      "step 3615, training accuracy 0.965116\n",
      "step 3620, training accuracy 0.976744\n",
      "step 3625, training accuracy 0.953488\n",
      "step 3630, training accuracy 0.988372\n",
      "step 3635, training accuracy 0.976744\n",
      "step 3640, training accuracy 0.965116\n",
      "step 3645, training accuracy 0.976744\n",
      "step 3650, training accuracy 0.94186\n",
      "step 3655, training accuracy 0.965116\n",
      "step 3660, training accuracy 0.976744\n",
      "step 3665, training accuracy 0.953488\n",
      "step 3670, training accuracy 0.976744\n",
      "step 3675, training accuracy 0.953488\n",
      "step 3680, training accuracy 0.988372\n",
      "step 3685, training accuracy 0.976744\n",
      "step 3690, training accuracy 0.965116\n",
      "step 3695, training accuracy 0.94186\n",
      "step 3700, training accuracy 0.953488\n",
      "\u001b[1m step 3700, validation accuracy \u001b[0;0m 0.981\n",
      "\u001b[1m The validation accuracy DID NOT improved from the last checkpoint \u001b[0;0m\n",
      "step 3705, training accuracy 1\n",
      "step 3710, training accuracy 0.976744\n",
      "step 3715, training accuracy 0.953488\n",
      "step 3720, training accuracy 0.976744\n",
      "step 3725, training accuracy 1\n",
      "step 3730, training accuracy 0.965116\n",
      "step 3735, training accuracy 0.965116\n",
      "step 3740, training accuracy 0.953488\n",
      "step 3745, training accuracy 0.988372\n",
      "step 3750, training accuracy 0.953488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 3755, training accuracy 1\n",
      "step 3760, training accuracy 0.94186\n",
      "step 3765, training accuracy 0.988372\n",
      "step 3770, training accuracy 0.988372\n",
      "step 3775, training accuracy 0.976744\n",
      "step 3780, training accuracy 0.930233\n",
      "step 3785, training accuracy 0.965116\n",
      "step 3790, training accuracy 0.965116\n",
      "step 3795, training accuracy 1\n",
      "step 3800, training accuracy 0.930233\n",
      "\u001b[1m step 3800, validation accuracy \u001b[0;0m 0.957\n",
      "\u001b[1m The validation accuracy DID NOT improved from the last checkpoint \u001b[0;0m\n",
      "step 3805, training accuracy 0.988372\n",
      "step 3810, training accuracy 0.94186\n",
      "step 3815, training accuracy 0.953488\n",
      "step 3820, training accuracy 0.976744\n",
      "step 3825, training accuracy 0.965116\n",
      "step 3830, training accuracy 0.953488\n",
      "step 3835, training accuracy 0.976744\n",
      "step 3840, training accuracy 0.988372\n",
      "step 3845, training accuracy 0.965116\n",
      "step 3850, training accuracy 0.94186\n",
      "step 3855, training accuracy 0.988372\n",
      "step 3860, training accuracy 1\n",
      "step 3865, training accuracy 0.965116\n",
      "step 3870, training accuracy 0.953488\n",
      "step 3875, training accuracy 0.976744\n",
      "step 3880, training accuracy 0.965116\n",
      "step 3885, training accuracy 1\n",
      "step 3890, training accuracy 0.953488\n",
      "step 3895, training accuracy 0.965116\n",
      "step 3900, training accuracy 0.94186\n",
      "\u001b[1m step 3900, validation accuracy \u001b[0;0m 0.961\n",
      "\u001b[1m The validation accuracy DID NOT improved from the last checkpoint \u001b[0;0m\n",
      "step 3905, training accuracy 0.965116\n",
      "step 3910, training accuracy 0.965116\n",
      "step 3915, training accuracy 0.953488\n",
      "step 3920, training accuracy 0.965116\n",
      "step 3925, training accuracy 0.953488\n",
      "step 3930, training accuracy 0.988372\n",
      "step 3935, training accuracy 0.976744\n",
      "step 3940, training accuracy 0.965116\n",
      "step 3945, training accuracy 0.965116\n",
      "step 3950, training accuracy 0.988372\n",
      "step 3955, training accuracy 0.988372\n",
      "step 3960, training accuracy 0.976744\n",
      "step 3965, training accuracy 0.976744\n",
      "step 3970, training accuracy 0.965116\n",
      "step 3975, training accuracy 0.988372\n",
      "step 3980, training accuracy 0.988372\n",
      "step 3985, training accuracy 0.918605\n",
      "step 3990, training accuracy 1\n",
      "step 3995, training accuracy 0.965116\n",
      "step 4000, training accuracy 0.930233\n",
      "\u001b[1m step 4000, validation accuracy \u001b[0;0m 0.969\n",
      "\u001b[1m The validation accuracy DID NOT improved from the last checkpoint \u001b[0;0m\n",
      "step 4005, training accuracy 0.965116\n",
      "step 4010, training accuracy 0.965116\n",
      "step 4015, training accuracy 0.976744\n",
      "step 4020, training accuracy 0.988372\n",
      "step 4025, training accuracy 0.930233\n",
      "step 4030, training accuracy 0.965116\n",
      "step 4035, training accuracy 0.953488\n",
      "step 4040, training accuracy 1\n",
      "step 4045, training accuracy 0.94186\n",
      "step 4050, training accuracy 0.988372\n",
      "step 4055, training accuracy 0.988372\n",
      "step 4060, training accuracy 1\n",
      "step 4065, training accuracy 0.988372\n",
      "step 4070, training accuracy 0.976744\n",
      "step 4075, training accuracy 0.976744\n",
      "step 4080, training accuracy 0.988372\n",
      "step 4085, training accuracy 1\n",
      "step 4090, training accuracy 0.976744\n",
      "step 4095, training accuracy 0.976744\n",
      "step 4100, training accuracy 0.976744\n",
      "\u001b[1m step 4100, validation accuracy \u001b[0;0m 0.976\n",
      "\u001b[1m The validation accuracy DID NOT improved from the last checkpoint \u001b[0;0m\n",
      "step 4105, training accuracy 1\n",
      "step 4110, training accuracy 0.976744\n",
      "step 4115, training accuracy 0.988372\n",
      "step 4120, training accuracy 0.976744\n",
      "step 4125, training accuracy 0.988372\n",
      "step 4130, training accuracy 0.976744\n",
      "step 4135, training accuracy 0.953488\n",
      "step 4140, training accuracy 0.976744\n",
      "step 4145, training accuracy 0.965116\n",
      "step 4150, training accuracy 0.988372\n",
      "step 4155, training accuracy 0.976744\n",
      "step 4160, training accuracy 0.965116\n",
      "step 4165, training accuracy 0.953488\n",
      "step 4170, training accuracy 0.953488\n",
      "step 4175, training accuracy 0.976744\n",
      "step 4180, training accuracy 0.988372\n",
      "step 4185, training accuracy 0.988372\n",
      "step 4190, training accuracy 0.965116\n",
      "step 4195, training accuracy 0.988372\n",
      "step 4200, training accuracy 0.965116\n",
      "\u001b[1m step 4200, validation accuracy \u001b[0;0m 0.962\n",
      "\u001b[1m The validation accuracy DID NOT improved from the last checkpoint \u001b[0;0m\n",
      "step 4205, training accuracy 0.965116\n",
      "step 4210, training accuracy 0.976744\n",
      "step 4215, training accuracy 0.953488\n",
      "step 4220, training accuracy 0.953488\n",
      "step 4225, training accuracy 0.965116\n",
      "step 4230, training accuracy 0.94186\n",
      "step 4235, training accuracy 0.953488\n",
      "step 4240, training accuracy 0.953488\n",
      "step 4245, training accuracy 1\n",
      "step 4250, training accuracy 0.965116\n",
      "step 4255, training accuracy 0.930233\n",
      "step 4260, training accuracy 0.94186\n",
      "step 4265, training accuracy 1\n",
      "step 4270, training accuracy 0.965116\n",
      "step 4275, training accuracy 0.976744\n",
      "step 4280, training accuracy 0.965116\n",
      "step 4285, training accuracy 0.94186\n",
      "step 4290, training accuracy 0.918605\n",
      "step 4295, training accuracy 0.965116\n",
      "step 4300, training accuracy 0.895349\n",
      "\u001b[1m step 4300, validation accuracy \u001b[0;0m 0.935\n",
      "\u001b[1m The validation accuracy DID NOT improved from the last checkpoint \u001b[0;0m\n",
      "step 4305, training accuracy 0.94186\n",
      "step 4310, training accuracy 0.988372\n",
      "step 4315, training accuracy 0.930233\n",
      "step 4320, training accuracy 0.965116\n",
      "step 4325, training accuracy 0.953488\n",
      "step 4330, training accuracy 0.988372\n",
      "step 4335, training accuracy 0.965116\n",
      "step 4340, training accuracy 0.965116\n",
      "step 4345, training accuracy 0.965116\n",
      "step 4350, training accuracy 0.965116\n",
      "step 4355, training accuracy 1\n",
      "step 4360, training accuracy 0.965116\n",
      "step 4365, training accuracy 0.976744\n",
      "step 4370, training accuracy 0.976744\n",
      "step 4375, training accuracy 0.988372\n",
      "step 4380, training accuracy 0.988372\n",
      "step 4385, training accuracy 0.976744\n",
      "step 4390, training accuracy 0.94186\n",
      "step 4395, training accuracy 0.953488\n",
      "step 4400, training accuracy 0.976744\n",
      "\u001b[1m step 4400, validation accuracy \u001b[0;0m 0.97\n",
      "\u001b[1m The validation accuracy DID NOT improved from the last checkpoint \u001b[0;0m\n",
      "step 4405, training accuracy 0.930233\n",
      "step 4410, training accuracy 0.94186\n",
      "step 4415, training accuracy 0.965116\n",
      "step 4420, training accuracy 0.965116\n",
      "step 4425, training accuracy 0.965116\n",
      "step 4430, training accuracy 0.953488\n",
      "step 4435, training accuracy 0.953488\n",
      "step 4440, training accuracy 0.953488\n",
      "step 4445, training accuracy 0.976744\n",
      "step 4450, training accuracy 0.953488\n",
      "step 4455, training accuracy 0.976744\n",
      "step 4460, training accuracy 0.988372\n",
      "step 4465, training accuracy 1\n",
      "step 4470, training accuracy 0.988372\n",
      "step 4475, training accuracy 0.988372\n",
      "step 4480, training accuracy 0.976744\n",
      "step 4485, training accuracy 0.976744\n",
      "step 4490, training accuracy 0.930233\n",
      "step 4495, training accuracy 0.988372\n",
      "step 4500, training accuracy 0.988372\n",
      "\u001b[1m step 4500, validation accuracy \u001b[0;0m 0.972\n",
      "\u001b[1m The validation accuracy DID NOT improved from the last checkpoint \u001b[0;0m\n",
      "step 4505, training accuracy 0.976744\n",
      "step 4510, training accuracy 0.965116\n",
      "step 4515, training accuracy 0.988372\n",
      "step 4520, training accuracy 1\n",
      "step 4525, training accuracy 0.965116\n",
      "step 4530, training accuracy 0.988372\n",
      "step 4535, training accuracy 0.976744\n",
      "step 4540, training accuracy 0.976744\n",
      "step 4545, training accuracy 0.953488\n",
      "step 4550, training accuracy 0.976744\n",
      "step 4555, training accuracy 0.976744\n",
      "step 4560, training accuracy 0.976744\n",
      "step 4565, training accuracy 0.988372\n",
      "step 4570, training accuracy 0.953488\n",
      "step 4575, training accuracy 0.976744\n",
      "step 4580, training accuracy 0.988372\n",
      "step 4585, training accuracy 0.976744\n",
      "step 4590, training accuracy 0.988372\n",
      "step 4595, training accuracy 0.976744\n",
      "step 4600, training accuracy 1\n",
      "\u001b[1m step 4600, validation accuracy \u001b[0;0m 0.976\n",
      "\u001b[1m The validation accuracy DID NOT improved from the last checkpoint \u001b[0;0m\n",
      "step 4605, training accuracy 0.988372\n",
      "step 4610, training accuracy 0.976744\n",
      "step 4615, training accuracy 1\n",
      "step 4620, training accuracy 0.930233\n",
      "step 4625, training accuracy 0.976744\n",
      "step 4630, training accuracy 0.965116\n",
      "step 4635, training accuracy 0.988372\n",
      "step 4640, training accuracy 0.965116\n",
      "step 4645, training accuracy 0.965116\n",
      "step 4650, training accuracy 0.988372\n",
      "step 4655, training accuracy 1\n",
      "step 4660, training accuracy 0.906977\n",
      "step 4665, training accuracy 0.930233\n",
      "step 4670, training accuracy 0.94186\n",
      "step 4675, training accuracy 0.976744\n",
      "step 4680, training accuracy 0.976744\n",
      "step 4685, training accuracy 0.965116\n",
      "step 4690, training accuracy 0.930233\n",
      "step 4695, training accuracy 0.953488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 4700, training accuracy 0.953488\n",
      "\u001b[1m step 4700, validation accuracy \u001b[0;0m 0.975\n",
      "\u001b[1m The validation accuracy DID NOT improved from the last checkpoint \u001b[0;0m\n",
      "step 4705, training accuracy 0.94186\n",
      "step 4710, training accuracy 0.94186\n",
      "step 4715, training accuracy 0.965116\n",
      "step 4720, training accuracy 0.965116\n",
      "step 4725, training accuracy 0.976744\n",
      "step 4730, training accuracy 0.988372\n",
      "step 4735, training accuracy 0.965116\n",
      "step 4740, training accuracy 0.965116\n",
      "step 4745, training accuracy 0.988372\n",
      "step 4750, training accuracy 0.965116\n",
      "step 4755, training accuracy 0.930233\n",
      "step 4760, training accuracy 0.953488\n",
      "step 4765, training accuracy 0.965116\n",
      "step 4770, training accuracy 1\n",
      "step 4775, training accuracy 0.988372\n",
      "step 4780, training accuracy 0.965116\n",
      "step 4785, training accuracy 0.965116\n",
      "step 4790, training accuracy 0.976744\n",
      "step 4795, training accuracy 0.930233\n",
      "step 4800, training accuracy 0.976744\n",
      "\u001b[1m step 4800, validation accuracy \u001b[0;0m 0.952\n",
      "\u001b[1m The validation accuracy DID NOT improved from the last checkpoint \u001b[0;0m\n",
      "step 4805, training accuracy 0.976744\n",
      "step 4810, training accuracy 0.953488\n",
      "step 4815, training accuracy 0.94186\n",
      "step 4820, training accuracy 0.976744\n",
      "step 4825, training accuracy 0.976744\n",
      "step 4830, training accuracy 0.953488\n",
      "step 4835, training accuracy 0.953488\n",
      "step 4840, training accuracy 0.965116\n",
      "step 4845, training accuracy 0.965116\n",
      "step 4850, training accuracy 0.976744\n",
      "step 4855, training accuracy 0.988372\n",
      "step 4860, training accuracy 0.976744\n",
      "step 4865, training accuracy 0.953488\n",
      "step 4870, training accuracy 0.988372\n",
      "step 4875, training accuracy 1\n",
      "step 4880, training accuracy 0.976744\n",
      "step 4885, training accuracy 0.965116\n",
      "step 4890, training accuracy 0.988372\n",
      "step 4895, training accuracy 0.94186\n",
      "step 4900, training accuracy 0.988372\n",
      "\u001b[1m step 4900, validation accuracy \u001b[0;0m 0.972\n",
      "\u001b[1m The validation accuracy DID NOT improved from the last checkpoint \u001b[0;0m\n",
      "step 4905, training accuracy 0.988372\n",
      "step 4910, training accuracy 0.976744\n",
      "step 4915, training accuracy 1\n",
      "step 4920, training accuracy 1\n",
      "step 4925, training accuracy 0.988372\n",
      "step 4930, training accuracy 0.976744\n",
      "step 4935, training accuracy 0.953488\n",
      "step 4940, training accuracy 0.976744\n",
      "step 4945, training accuracy 0.953488\n",
      "step 4950, training accuracy 0.988372\n",
      "step 4955, training accuracy 0.988372\n",
      "step 4960, training accuracy 0.988372\n",
      "step 4965, training accuracy 0.965116\n",
      "step 4970, training accuracy 0.988372\n",
      "step 4975, training accuracy 0.976744\n",
      "step 4980, training accuracy 0.976744\n",
      "step 4985, training accuracy 0.965116\n",
      "step 4990, training accuracy 0.976744\n",
      "step 4995, training accuracy 1\n",
      "step 0, test accuracy 0.971\n",
      "step 5, test accuracy 0.977\n",
      "step 10, test accuracy 0.971\n",
      "step 15, test accuracy 0.975\n",
      "step 20, test accuracy 0.971\n",
      "step 25, test accuracy 0.977\n",
      "step 30, test accuracy 0.974\n",
      "step 35, test accuracy 0.975\n",
      "step 40, test accuracy 0.975\n",
      "step 45, test accuracy 0.976\n",
      "step 50, test accuracy 0.977\n",
      "step 55, test accuracy 0.979\n",
      "step 60, test accuracy 0.976\n",
      "step 65, test accuracy 0.982\n",
      "step 70, test accuracy 0.973\n",
      "step 75, test accuracy 0.984\n",
      "step 80, test accuracy 0.974\n",
      "step 85, test accuracy 0.981\n",
      "step 90, test accuracy 0.972\n",
      "step 95, test accuracy 0.98\n",
      "step 100, test accuracy 0.974\n",
      "step 105, test accuracy 0.981\n",
      "step 110, test accuracy 0.975\n",
      "step 115, test accuracy 0.981\n",
      "step 120, test accuracy 0.978\n",
      "step 125, test accuracy 0.981\n",
      "step 130, test accuracy 0.977\n",
      "step 135, test accuracy 0.981\n",
      "step 140, test accuracy 0.976\n",
      "step 145, test accuracy 0.985\n",
      "step 150, test accuracy 0.974\n",
      "step 155, test accuracy 0.985\n",
      "step 160, test accuracy 0.975\n",
      "step 165, test accuracy 0.984\n",
      "step 170, test accuracy 0.974\n",
      "step 175, test accuracy 0.982\n",
      "step 180, test accuracy 0.978\n",
      "step 185, test accuracy 0.984\n",
      "step 190, test accuracy 0.977\n",
      "step 195, test accuracy 0.984\n",
      "step 200, test accuracy 0.975\n",
      "step 205, test accuracy 0.971\n",
      "step 210, test accuracy 0.977\n",
      "step 215, test accuracy 0.969\n",
      "step 220, test accuracy 0.977\n",
      "step 225, test accuracy 0.971\n",
      "step 230, test accuracy 0.975\n",
      "step 235, test accuracy 0.976\n",
      "step 240, test accuracy 0.978\n",
      "step 245, test accuracy 0.977\n",
      "step 250, test accuracy 0.977\n",
      "step 255, test accuracy 0.975\n",
      "step 260, test accuracy 0.98\n",
      "step 265, test accuracy 0.974\n",
      "step 270, test accuracy 0.982\n",
      "step 275, test accuracy 0.973\n",
      "step 280, test accuracy 0.981\n",
      "step 285, test accuracy 0.972\n",
      "step 290, test accuracy 0.981\n",
      "step 295, test accuracy 0.973\n",
      "step 300, test accuracy 0.98\n",
      "step 305, test accuracy 0.975\n",
      "step 310, test accuracy 0.981\n",
      "step 315, test accuracy 0.978\n",
      "step 320, test accuracy 0.981\n",
      "step 325, test accuracy 0.977\n",
      "step 330, test accuracy 0.983\n",
      "step 335, test accuracy 0.977\n",
      "step 340, test accuracy 0.984\n",
      "step 345, test accuracy 0.975\n",
      "step 350, test accuracy 0.985\n",
      "step 355, test accuracy 0.975\n",
      "step 360, test accuracy 0.984\n",
      "step 365, test accuracy 0.974\n",
      "step 370, test accuracy 0.983\n",
      "step 375, test accuracy 0.977\n",
      "step 380, test accuracy 0.983\n",
      "step 385, test accuracy 0.977\n",
      "step 390, test accuracy 0.983\n",
      "step 395, test accuracy 0.976\n",
      "step 400, test accuracy 0.971\n",
      "step 405, test accuracy 0.977\n",
      "step 410, test accuracy 0.971\n",
      "step 415, test accuracy 0.977\n",
      "step 420, test accuracy 0.969\n",
      "step 425, test accuracy 0.976\n",
      "step 430, test accuracy 0.974\n",
      "step 435, test accuracy 0.976\n",
      "step 440, test accuracy 0.975\n",
      "step 445, test accuracy 0.975\n",
      "step 450, test accuracy 0.976\n",
      "step 455, test accuracy 0.98\n",
      "step 460, test accuracy 0.977\n",
      "step 465, test accuracy 0.983\n",
      "step 470, test accuracy 0.974\n",
      "step 475, test accuracy 0.982\n",
      "step 480, test accuracy 0.973\n",
      "step 485, test accuracy 0.981\n",
      "step 490, test accuracy 0.972\n",
      "step 495, test accuracy 0.98\n",
      "step 500, test accuracy 0.974\n",
      "step 505, test accuracy 0.981\n",
      "step 510, test accuracy 0.977\n",
      "step 515, test accuracy 0.981\n",
      "step 520, test accuracy 0.978\n",
      "step 525, test accuracy 0.982\n",
      "step 530, test accuracy 0.977\n",
      "step 535, test accuracy 0.982\n",
      "step 540, test accuracy 0.975\n",
      "step 545, test accuracy 0.985\n",
      "step 550, test accuracy 0.974\n",
      "step 555, test accuracy 0.984\n",
      "step 560, test accuracy 0.974\n",
      "step 565, test accuracy 0.985\n",
      "step 570, test accuracy 0.975\n",
      "step 575, test accuracy 0.982\n",
      "step 580, test accuracy 0.977\n",
      "step 585, test accuracy 0.985\n",
      "step 590, test accuracy 0.976\n",
      "step 595, test accuracy 0.984\n",
      "step 600, test accuracy 0.976\n",
      "step 605, test accuracy 0.969\n",
      "step 610, test accuracy 0.976\n",
      "step 615, test accuracy 0.971\n",
      "step 620, test accuracy 0.977\n",
      "step 625, test accuracy 0.973\n",
      "step 630, test accuracy 0.976\n",
      "step 635, test accuracy 0.976\n",
      "step 640, test accuracy 0.976\n",
      "step 645, test accuracy 0.978\n",
      "step 650, test accuracy 0.979\n",
      "step 655, test accuracy 0.976\n",
      "step 660, test accuracy 0.981\n",
      "step 665, test accuracy 0.974\n",
      "step 670, test accuracy 0.983\n",
      "step 675, test accuracy 0.974\n",
      "step 680, test accuracy 0.982\n",
      "step 685, test accuracy 0.973\n",
      "step 690, test accuracy 0.98\n",
      "step 695, test accuracy 0.973\n",
      "step 700, test accuracy 0.981\n",
      "step 705, test accuracy 0.975\n",
      "step 710, test accuracy 0.981\n",
      "step 715, test accuracy 0.978\n",
      "step 720, test accuracy 0.981\n",
      "step 725, test accuracy 0.977\n",
      "step 730, test accuracy 0.982\n",
      "step 735, test accuracy 0.977\n",
      "step 740, test accuracy 0.984\n",
      "step 745, test accuracy 0.974\n",
      "step 750, test accuracy 0.985\n",
      "step 755, test accuracy 0.975\n",
      "step 760, test accuracy 0.985\n",
      "step 765, test accuracy 0.974\n",
      "step 770, test accuracy 0.982\n",
      "step 775, test accuracy 0.977\n",
      "step 780, test accuracy 0.983\n",
      "step 785, test accuracy 0.977\n",
      "step 790, test accuracy 0.984\n",
      "step 795, test accuracy 0.975\n",
      "step 800, test accuracy 0.97\n",
      "step 805, test accuracy 0.978\n",
      "step 810, test accuracy 0.97\n",
      "step 815, test accuracy 0.977\n",
      "step 820, test accuracy 0.969\n",
      "step 825, test accuracy 0.976\n",
      "step 830, test accuracy 0.975\n",
      "step 835, test accuracy 0.977\n",
      "step 840, test accuracy 0.977\n",
      "step 845, test accuracy 0.977\n",
      "step 850, test accuracy 0.975\n",
      "step 855, test accuracy 0.98\n",
      "step 860, test accuracy 0.976\n",
      "step 865, test accuracy 0.981\n",
      "step 870, test accuracy 0.973\n",
      "step 875, test accuracy 0.981\n",
      "step 880, test accuracy 0.973\n",
      "step 885, test accuracy 0.98\n",
      "step 890, test accuracy 0.973\n",
      "step 895, test accuracy 0.981\n",
      "step 900, test accuracy 0.974\n",
      "step 905, test accuracy 0.98\n",
      "step 910, test accuracy 0.977\n",
      "step 915, test accuracy 0.982\n",
      "step 920, test accuracy 0.978\n",
      "step 925, test accuracy 0.982\n",
      "step 930, test accuracy 0.977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 935, test accuracy 0.983\n",
      "step 940, test accuracy 0.975\n",
      "step 945, test accuracy 0.985\n",
      "step 950, test accuracy 0.975\n",
      "step 955, test accuracy 0.984\n",
      "step 960, test accuracy 0.974\n",
      "step 965, test accuracy 0.984\n",
      "step 970, test accuracy 0.976\n",
      "step 975, test accuracy 0.983\n",
      "step 980, test accuracy 0.977\n",
      "step 985, test accuracy 0.984\n",
      "step 990, test accuracy 0.977\n",
      "step 995, test accuracy 0.971\n",
      "step 1000, test accuracy 0.977\n",
      "step 1005, test accuracy 0.971\n",
      "step 1010, test accuracy 0.975\n",
      "step 1015, test accuracy 0.971\n",
      "step 1020, test accuracy 0.977\n",
      "step 1025, test accuracy 0.974\n",
      "step 1030, test accuracy 0.975\n",
      "step 1035, test accuracy 0.975\n",
      "step 1040, test accuracy 0.976\n",
      "step 1045, test accuracy 0.977\n",
      "step 1050, test accuracy 0.979\n",
      "step 1055, test accuracy 0.976\n",
      "step 1060, test accuracy 0.982\n",
      "step 1065, test accuracy 0.973\n",
      "step 1070, test accuracy 0.984\n",
      "step 1075, test accuracy 0.974\n",
      "step 1080, test accuracy 0.981\n",
      "step 1085, test accuracy 0.972\n",
      "step 1090, test accuracy 0.98\n",
      "step 1095, test accuracy 0.974\n",
      "step 1100, test accuracy 0.981\n",
      "step 1105, test accuracy 0.975\n",
      "step 1110, test accuracy 0.981\n",
      "step 1115, test accuracy 0.978\n",
      "step 1120, test accuracy 0.981\n",
      "step 1125, test accuracy 0.977\n",
      "step 1130, test accuracy 0.981\n",
      "step 1135, test accuracy 0.976\n",
      "step 1140, test accuracy 0.985\n",
      "step 1145, test accuracy 0.974\n",
      "step 1150, test accuracy 0.985\n",
      "step 1155, test accuracy 0.975\n",
      "step 1160, test accuracy 0.984\n",
      "step 1165, test accuracy 0.974\n",
      "step 1170, test accuracy 0.982\n",
      "step 1175, test accuracy 0.978\n",
      "step 1180, test accuracy 0.984\n",
      "step 1185, test accuracy 0.977\n",
      "step 1190, test accuracy 0.984\n",
      "step 1195, test accuracy 0.975\n",
      "step 1200, test accuracy 0.971\n",
      "step 1205, test accuracy 0.977\n",
      "step 1210, test accuracy 0.969\n",
      "step 1215, test accuracy 0.977\n",
      "step 1220, test accuracy 0.971\n",
      "step 1225, test accuracy 0.975\n",
      "step 1230, test accuracy 0.976\n",
      "step 1235, test accuracy 0.978\n",
      "step 1240, test accuracy 0.977\n",
      "step 1245, test accuracy 0.977\n",
      "step 1250, test accuracy 0.975\n",
      "step 1255, test accuracy 0.98\n",
      "step 1260, test accuracy 0.974\n",
      "step 1265, test accuracy 0.982\n",
      "step 1270, test accuracy 0.973\n",
      "step 1275, test accuracy 0.981\n",
      "step 1280, test accuracy 0.972\n",
      "step 1285, test accuracy 0.981\n",
      "step 1290, test accuracy 0.973\n",
      "step 1295, test accuracy 0.98\n",
      "step 1300, test accuracy 0.975\n",
      "step 1305, test accuracy 0.981\n",
      "step 1310, test accuracy 0.978\n",
      "step 1315, test accuracy 0.981\n",
      "step 1320, test accuracy 0.977\n",
      "step 1325, test accuracy 0.983\n",
      "step 1330, test accuracy 0.977\n",
      "step 1335, test accuracy 0.984\n",
      "step 1340, test accuracy 0.975\n",
      "step 1345, test accuracy 0.985\n",
      "step 1350, test accuracy 0.975\n",
      "step 1355, test accuracy 0.984\n",
      "step 1360, test accuracy 0.974\n",
      "step 1365, test accuracy 0.983\n",
      "step 1370, test accuracy 0.977\n",
      "step 1375, test accuracy 0.983\n",
      "step 1380, test accuracy 0.977\n",
      "step 1385, test accuracy 0.983\n",
      "step 1390, test accuracy 0.976\n",
      "step 1395, test accuracy 0.971\n",
      "step 1400, test accuracy 0.977\n",
      "step 1405, test accuracy 0.971\n",
      "step 1410, test accuracy 0.977\n",
      "step 1415, test accuracy 0.969\n",
      "step 1420, test accuracy 0.976\n",
      "step 1425, test accuracy 0.974\n",
      "step 1430, test accuracy 0.976\n",
      "step 1435, test accuracy 0.975\n",
      "step 1440, test accuracy 0.975\n",
      "step 1445, test accuracy 0.976\n",
      "step 1450, test accuracy 0.98\n",
      "step 1455, test accuracy 0.977\n",
      "step 1460, test accuracy 0.983\n",
      "step 1465, test accuracy 0.974\n",
      "step 1470, test accuracy 0.982\n",
      "step 1475, test accuracy 0.973\n",
      "step 1480, test accuracy 0.981\n",
      "step 1485, test accuracy 0.972\n",
      "step 1490, test accuracy 0.98\n",
      "step 1495, test accuracy 0.974\n",
      "step 1500, test accuracy 0.981\n",
      "step 1505, test accuracy 0.977\n",
      "step 1510, test accuracy 0.981\n",
      "step 1515, test accuracy 0.978\n",
      "step 1520, test accuracy 0.982\n",
      "step 1525, test accuracy 0.977\n",
      "step 1530, test accuracy 0.982\n",
      "step 1535, test accuracy 0.975\n",
      "step 1540, test accuracy 0.985\n",
      "step 1545, test accuracy 0.974\n",
      "step 1550, test accuracy 0.984\n",
      "step 1555, test accuracy 0.974\n",
      "step 1560, test accuracy 0.985\n",
      "step 1565, test accuracy 0.975\n",
      "step 1570, test accuracy 0.982\n",
      "step 1575, test accuracy 0.977\n",
      "step 1580, test accuracy 0.985\n",
      "step 1585, test accuracy 0.976\n",
      "step 1590, test accuracy 0.984\n",
      "step 1595, test accuracy 0.976\n",
      "step 1600, test accuracy 0.969\n",
      "step 1605, test accuracy 0.976\n",
      "step 1610, test accuracy 0.971\n",
      "step 1615, test accuracy 0.977\n",
      "step 1620, test accuracy 0.973\n",
      "step 1625, test accuracy 0.976\n",
      "step 1630, test accuracy 0.976\n",
      "step 1635, test accuracy 0.976\n",
      "step 1640, test accuracy 0.978\n",
      "step 1645, test accuracy 0.979\n",
      "step 1650, test accuracy 0.976\n",
      "step 1655, test accuracy 0.981\n",
      "step 1660, test accuracy 0.974\n",
      "step 1665, test accuracy 0.983\n",
      "step 1670, test accuracy 0.974\n",
      "step 1675, test accuracy 0.982\n",
      "step 1680, test accuracy 0.973\n",
      "step 1685, test accuracy 0.98\n",
      "step 1690, test accuracy 0.973\n",
      "step 1695, test accuracy 0.981\n",
      "step 1700, test accuracy 0.975\n",
      "step 1705, test accuracy 0.981\n",
      "step 1710, test accuracy 0.978\n",
      "step 1715, test accuracy 0.981\n",
      "step 1720, test accuracy 0.977\n",
      "step 1725, test accuracy 0.982\n",
      "step 1730, test accuracy 0.977\n",
      "step 1735, test accuracy 0.984\n",
      "step 1740, test accuracy 0.974\n",
      "step 1745, test accuracy 0.985\n",
      "step 1750, test accuracy 0.975\n",
      "step 1755, test accuracy 0.985\n",
      "step 1760, test accuracy 0.974\n",
      "step 1765, test accuracy 0.982\n",
      "step 1770, test accuracy 0.977\n",
      "step 1775, test accuracy 0.983\n",
      "step 1780, test accuracy 0.977\n",
      "step 1785, test accuracy 0.984\n",
      "step 1790, test accuracy 0.975\n",
      "step 1795, test accuracy 0.97\n",
      "step 1800, test accuracy 0.978\n",
      "step 1805, test accuracy 0.97\n",
      "step 1810, test accuracy 0.977\n",
      "step 1815, test accuracy 0.969\n",
      "step 1820, test accuracy 0.976\n",
      "step 1825, test accuracy 0.975\n",
      "step 1830, test accuracy 0.977\n",
      "step 1835, test accuracy 0.977\n",
      "step 1840, test accuracy 0.977\n",
      "step 1845, test accuracy 0.975\n",
      "step 1850, test accuracy 0.98\n",
      "step 1855, test accuracy 0.976\n",
      "step 1860, test accuracy 0.981\n",
      "step 1865, test accuracy 0.973\n",
      "step 1870, test accuracy 0.981\n",
      "step 1875, test accuracy 0.973\n",
      "step 1880, test accuracy 0.98\n",
      "step 1885, test accuracy 0.973\n",
      "step 1890, test accuracy 0.981\n",
      "step 1895, test accuracy 0.974\n",
      "step 1900, test accuracy 0.98\n",
      "step 1905, test accuracy 0.977\n",
      "step 1910, test accuracy 0.982\n",
      "step 1915, test accuracy 0.978\n",
      "step 1920, test accuracy 0.982\n",
      "step 1925, test accuracy 0.977\n",
      "step 1930, test accuracy 0.983\n",
      "step 1935, test accuracy 0.975\n",
      "step 1940, test accuracy 0.985\n",
      "step 1945, test accuracy 0.975\n",
      "step 1950, test accuracy 0.984\n",
      "step 1955, test accuracy 0.974\n",
      "step 1960, test accuracy 0.984\n",
      "step 1965, test accuracy 0.976\n",
      "step 1970, test accuracy 0.983\n",
      "step 1975, test accuracy 0.977\n",
      "step 1980, test accuracy 0.984\n",
      "step 1985, test accuracy 0.977\n",
      "step 1990, test accuracy 0.971\n",
      "step 1995, test accuracy 0.977\n",
      "step 2000, test accuracy 0.971\n",
      "step 2005, test accuracy 0.975\n",
      "step 2010, test accuracy 0.971\n",
      "step 2015, test accuracy 0.977\n",
      "step 2020, test accuracy 0.974\n",
      "step 2025, test accuracy 0.975\n",
      "step 2030, test accuracy 0.975\n",
      "step 2035, test accuracy 0.976\n",
      "step 2040, test accuracy 0.977\n",
      "step 2045, test accuracy 0.979\n",
      "step 2050, test accuracy 0.976\n",
      "step 2055, test accuracy 0.982\n",
      "step 2060, test accuracy 0.973\n",
      "step 2065, test accuracy 0.984\n",
      "step 2070, test accuracy 0.974\n",
      "step 2075, test accuracy 0.981\n",
      "step 2080, test accuracy 0.972\n",
      "step 2085, test accuracy 0.98\n",
      "step 2090, test accuracy 0.974\n",
      "step 2095, test accuracy 0.981\n",
      "step 2100, test accuracy 0.975\n",
      "step 2105, test accuracy 0.981\n",
      "step 2110, test accuracy 0.978\n",
      "step 2115, test accuracy 0.981\n",
      "step 2120, test accuracy 0.977\n",
      "step 2125, test accuracy 0.981\n",
      "step 2130, test accuracy 0.976\n",
      "step 2135, test accuracy 0.985\n",
      "step 2140, test accuracy 0.974\n",
      "step 2145, test accuracy 0.985\n",
      "step 2150, test accuracy 0.975\n",
      "step 2155, test accuracy 0.984\n",
      "step 2160, test accuracy 0.974\n",
      "step 2165, test accuracy 0.982\n",
      "step 2170, test accuracy 0.978\n",
      "step 2175, test accuracy 0.984\n",
      "step 2180, test accuracy 0.977\n",
      "step 2185, test accuracy 0.984\n",
      "step 2190, test accuracy 0.975\n",
      "step 2195, test accuracy 0.971\n",
      "step 2200, test accuracy 0.977\n",
      "step 2205, test accuracy 0.969\n",
      "step 2210, test accuracy 0.977\n",
      "step 2215, test accuracy 0.971\n",
      "step 2220, test accuracy 0.975\n",
      "step 2225, test accuracy 0.976\n",
      "step 2230, test accuracy 0.978\n",
      "step 2235, test accuracy 0.977\n",
      "step 2240, test accuracy 0.977\n",
      "step 2245, test accuracy 0.975\n",
      "step 2250, test accuracy 0.98\n",
      "step 2255, test accuracy 0.974\n",
      "step 2260, test accuracy 0.982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2265, test accuracy 0.973\n",
      "step 2270, test accuracy 0.981\n",
      "step 2275, test accuracy 0.972\n",
      "step 2280, test accuracy 0.981\n",
      "step 2285, test accuracy 0.973\n",
      "step 2290, test accuracy 0.98\n",
      "step 2295, test accuracy 0.975\n",
      "step 2300, test accuracy 0.981\n",
      "step 2305, test accuracy 0.978\n",
      "step 2310, test accuracy 0.981\n",
      "step 2315, test accuracy 0.977\n",
      "step 2320, test accuracy 0.983\n",
      "step 2325, test accuracy 0.977\n",
      "step 2330, test accuracy 0.984\n",
      "step 2335, test accuracy 0.975\n",
      "step 2340, test accuracy 0.985\n",
      "step 2345, test accuracy 0.975\n",
      "step 2350, test accuracy 0.984\n",
      "step 2355, test accuracy 0.974\n",
      "step 2360, test accuracy 0.983\n",
      "step 2365, test accuracy 0.977\n",
      "step 2370, test accuracy 0.983\n",
      "step 2375, test accuracy 0.977\n",
      "step 2380, test accuracy 0.983\n",
      "step 2385, test accuracy 0.976\n",
      "step 2390, test accuracy 0.971\n",
      "step 2395, test accuracy 0.977\n",
      "step 2400, test accuracy 0.971\n",
      "step 2405, test accuracy 0.977\n",
      "step 2410, test accuracy 0.969\n",
      "step 2415, test accuracy 0.976\n",
      "step 2420, test accuracy 0.974\n",
      "step 2425, test accuracy 0.976\n",
      "step 2430, test accuracy 0.975\n",
      "step 2435, test accuracy 0.975\n",
      "step 2440, test accuracy 0.976\n",
      "step 2445, test accuracy 0.98\n",
      "step 2450, test accuracy 0.977\n",
      "step 2455, test accuracy 0.983\n",
      "step 2460, test accuracy 0.974\n",
      "step 2465, test accuracy 0.982\n",
      "step 2470, test accuracy 0.973\n",
      "step 2475, test accuracy 0.981\n",
      "step 2480, test accuracy 0.972\n",
      "step 2485, test accuracy 0.98\n",
      "step 2490, test accuracy 0.974\n",
      "step 2495, test accuracy 0.981\n",
      "step 2500, test accuracy 0.977\n",
      "step 2505, test accuracy 0.981\n",
      "step 2510, test accuracy 0.978\n",
      "step 2515, test accuracy 0.982\n",
      "step 2520, test accuracy 0.977\n",
      "step 2525, test accuracy 0.982\n",
      "step 2530, test accuracy 0.975\n",
      "step 2535, test accuracy 0.985\n",
      "step 2540, test accuracy 0.974\n",
      "step 2545, test accuracy 0.984\n",
      "step 2550, test accuracy 0.974\n",
      "step 2555, test accuracy 0.985\n",
      "step 2560, test accuracy 0.975\n",
      "step 2565, test accuracy 0.982\n",
      "step 2570, test accuracy 0.977\n",
      "step 2575, test accuracy 0.985\n",
      "step 2580, test accuracy 0.976\n",
      "step 2585, test accuracy 0.984\n",
      "step 2590, test accuracy 0.976\n",
      "step 2595, test accuracy 0.969\n",
      "step 2600, test accuracy 0.976\n",
      "step 2605, test accuracy 0.971\n",
      "step 2610, test accuracy 0.977\n",
      "step 2615, test accuracy 0.973\n",
      "step 2620, test accuracy 0.976\n",
      "step 2625, test accuracy 0.976\n",
      "step 2630, test accuracy 0.976\n",
      "step 2635, test accuracy 0.978\n",
      "step 2640, test accuracy 0.979\n",
      "step 2645, test accuracy 0.976\n",
      "step 2650, test accuracy 0.981\n",
      "step 2655, test accuracy 0.974\n",
      "step 2660, test accuracy 0.983\n",
      "step 2665, test accuracy 0.974\n",
      "step 2670, test accuracy 0.982\n",
      "step 2675, test accuracy 0.973\n",
      "step 2680, test accuracy 0.98\n",
      "step 2685, test accuracy 0.973\n",
      "step 2690, test accuracy 0.981\n",
      "step 2695, test accuracy 0.975\n",
      "step 2700, test accuracy 0.981\n",
      "step 2705, test accuracy 0.978\n",
      "step 2710, test accuracy 0.981\n",
      "step 2715, test accuracy 0.977\n",
      "step 2720, test accuracy 0.982\n",
      "step 2725, test accuracy 0.977\n",
      "step 2730, test accuracy 0.984\n",
      "step 2735, test accuracy 0.974\n",
      "step 2740, test accuracy 0.985\n",
      "step 2745, test accuracy 0.975\n",
      "step 2750, test accuracy 0.985\n",
      "step 2755, test accuracy 0.974\n",
      "step 2760, test accuracy 0.982\n",
      "step 2765, test accuracy 0.977\n",
      "step 2770, test accuracy 0.983\n",
      "step 2775, test accuracy 0.977\n",
      "step 2780, test accuracy 0.984\n",
      "step 2785, test accuracy 0.975\n",
      "step 2790, test accuracy 0.97\n",
      "step 2795, test accuracy 0.978\n",
      "step 2800, test accuracy 0.97\n",
      "step 2805, test accuracy 0.977\n",
      "step 2810, test accuracy 0.969\n",
      "step 2815, test accuracy 0.976\n",
      "step 2820, test accuracy 0.975\n",
      "step 2825, test accuracy 0.977\n",
      "step 2830, test accuracy 0.977\n",
      "step 2835, test accuracy 0.977\n",
      "step 2840, test accuracy 0.975\n",
      "step 2845, test accuracy 0.98\n",
      "step 2850, test accuracy 0.976\n",
      "step 2855, test accuracy 0.981\n",
      "step 2860, test accuracy 0.973\n",
      "step 2865, test accuracy 0.981\n",
      "step 2870, test accuracy 0.973\n",
      "step 2875, test accuracy 0.98\n",
      "step 2880, test accuracy 0.973\n",
      "step 2885, test accuracy 0.981\n",
      "step 2890, test accuracy 0.974\n",
      "step 2895, test accuracy 0.98\n",
      "step 2900, test accuracy 0.977\n",
      "step 2905, test accuracy 0.982\n",
      "step 2910, test accuracy 0.978\n",
      "step 2915, test accuracy 0.982\n",
      "step 2920, test accuracy 0.977\n",
      "step 2925, test accuracy 0.983\n",
      "step 2930, test accuracy 0.975\n",
      "step 2935, test accuracy 0.985\n",
      "step 2940, test accuracy 0.975\n",
      "step 2945, test accuracy 0.984\n",
      "step 2950, test accuracy 0.974\n",
      "step 2955, test accuracy 0.984\n",
      "step 2960, test accuracy 0.976\n",
      "step 2965, test accuracy 0.983\n",
      "step 2970, test accuracy 0.977\n",
      "step 2975, test accuracy 0.984\n",
      "step 2980, test accuracy 0.977\n",
      "step 2985, test accuracy 0.971\n",
      "step 2990, test accuracy 0.977\n",
      "step 2995, test accuracy 0.971\n",
      "step 3000, test accuracy 0.975\n",
      "step 3005, test accuracy 0.971\n",
      "step 3010, test accuracy 0.977\n",
      "step 3015, test accuracy 0.974\n",
      "step 3020, test accuracy 0.975\n",
      "step 3025, test accuracy 0.975\n",
      "step 3030, test accuracy 0.976\n",
      "step 3035, test accuracy 0.977\n",
      "step 3040, test accuracy 0.979\n",
      "step 3045, test accuracy 0.976\n",
      "step 3050, test accuracy 0.982\n",
      "step 3055, test accuracy 0.973\n",
      "step 3060, test accuracy 0.984\n",
      "step 3065, test accuracy 0.974\n",
      "step 3070, test accuracy 0.981\n",
      "step 3075, test accuracy 0.972\n",
      "step 3080, test accuracy 0.98\n",
      "step 3085, test accuracy 0.974\n",
      "step 3090, test accuracy 0.981\n",
      "step 3095, test accuracy 0.975\n",
      "step 3100, test accuracy 0.981\n",
      "step 3105, test accuracy 0.978\n",
      "step 3110, test accuracy 0.981\n",
      "step 3115, test accuracy 0.977\n",
      "step 3120, test accuracy 0.981\n",
      "step 3125, test accuracy 0.976\n",
      "step 3130, test accuracy 0.985\n",
      "step 3135, test accuracy 0.974\n",
      "step 3140, test accuracy 0.985\n",
      "step 3145, test accuracy 0.975\n",
      "step 3150, test accuracy 0.984\n",
      "step 3155, test accuracy 0.974\n",
      "step 3160, test accuracy 0.982\n",
      "step 3165, test accuracy 0.978\n",
      "step 3170, test accuracy 0.984\n",
      "step 3175, test accuracy 0.977\n",
      "step 3180, test accuracy 0.984\n",
      "step 3185, test accuracy 0.975\n",
      "step 3190, test accuracy 0.971\n",
      "step 3195, test accuracy 0.977\n",
      "step 3200, test accuracy 0.969\n",
      "step 3205, test accuracy 0.977\n",
      "step 3210, test accuracy 0.971\n",
      "step 3215, test accuracy 0.975\n",
      "step 3220, test accuracy 0.976\n",
      "step 3225, test accuracy 0.978\n",
      "step 3230, test accuracy 0.977\n",
      "step 3235, test accuracy 0.977\n",
      "step 3240, test accuracy 0.975\n",
      "step 3245, test accuracy 0.98\n",
      "step 3250, test accuracy 0.974\n",
      "step 3255, test accuracy 0.982\n",
      "step 3260, test accuracy 0.973\n",
      "step 3265, test accuracy 0.981\n",
      "step 3270, test accuracy 0.972\n",
      "step 3275, test accuracy 0.981\n",
      "step 3280, test accuracy 0.973\n",
      "step 3285, test accuracy 0.98\n",
      "step 3290, test accuracy 0.975\n",
      "step 3295, test accuracy 0.981\n",
      "step 3300, test accuracy 0.978\n",
      "step 3305, test accuracy 0.981\n",
      "step 3310, test accuracy 0.977\n",
      "step 3315, test accuracy 0.983\n",
      "step 3320, test accuracy 0.977\n",
      "step 3325, test accuracy 0.984\n",
      "step 3330, test accuracy 0.975\n",
      "step 3335, test accuracy 0.985\n",
      "step 3340, test accuracy 0.975\n",
      "step 3345, test accuracy 0.984\n",
      "step 3350, test accuracy 0.974\n",
      "step 3355, test accuracy 0.983\n",
      "step 3360, test accuracy 0.977\n",
      "step 3365, test accuracy 0.983\n",
      "step 3370, test accuracy 0.977\n",
      "step 3375, test accuracy 0.983\n",
      "step 3380, test accuracy 0.976\n",
      "step 3385, test accuracy 0.971\n",
      "step 3390, test accuracy 0.977\n",
      "step 3395, test accuracy 0.971\n",
      "step 3400, test accuracy 0.977\n",
      "step 3405, test accuracy 0.969\n",
      "step 3410, test accuracy 0.976\n",
      "step 3415, test accuracy 0.974\n",
      "step 3420, test accuracy 0.976\n",
      "step 3425, test accuracy 0.975\n",
      "step 3430, test accuracy 0.975\n",
      "step 3435, test accuracy 0.976\n",
      "step 3440, test accuracy 0.98\n",
      "step 3445, test accuracy 0.977\n",
      "step 3450, test accuracy 0.983\n",
      "step 3455, test accuracy 0.974\n",
      "step 3460, test accuracy 0.982\n",
      "step 3465, test accuracy 0.973\n",
      "step 3470, test accuracy 0.981\n",
      "step 3475, test accuracy 0.972\n",
      "step 3480, test accuracy 0.98\n",
      "step 3485, test accuracy 0.974\n",
      "step 3490, test accuracy 0.981\n",
      "step 3495, test accuracy 0.977\n",
      "step 3500, test accuracy 0.981\n",
      "step 3505, test accuracy 0.978\n",
      "step 3510, test accuracy 0.982\n",
      "step 3515, test accuracy 0.977\n",
      "step 3520, test accuracy 0.982\n",
      "step 3525, test accuracy 0.975\n",
      "step 3530, test accuracy 0.985\n",
      "step 3535, test accuracy 0.974\n",
      "step 3540, test accuracy 0.984\n",
      "step 3545, test accuracy 0.974\n",
      "step 3550, test accuracy 0.985\n",
      "step 3555, test accuracy 0.975\n",
      "step 3560, test accuracy 0.982\n",
      "step 3565, test accuracy 0.977\n",
      "step 3570, test accuracy 0.985\n",
      "step 3575, test accuracy 0.976\n",
      "step 3580, test accuracy 0.984\n",
      "step 3585, test accuracy 0.976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 3590, test accuracy 0.969\n",
      "step 3595, test accuracy 0.976\n",
      "step 3600, test accuracy 0.971\n",
      "step 3605, test accuracy 0.977\n",
      "step 3610, test accuracy 0.973\n",
      "step 3615, test accuracy 0.976\n",
      "step 3620, test accuracy 0.976\n",
      "step 3625, test accuracy 0.976\n",
      "step 3630, test accuracy 0.978\n",
      "step 3635, test accuracy 0.979\n",
      "step 3640, test accuracy 0.976\n",
      "step 3645, test accuracy 0.981\n",
      "step 3650, test accuracy 0.974\n",
      "step 3655, test accuracy 0.983\n",
      "step 3660, test accuracy 0.974\n",
      "step 3665, test accuracy 0.982\n",
      "step 3670, test accuracy 0.973\n",
      "step 3675, test accuracy 0.98\n",
      "step 3680, test accuracy 0.973\n",
      "step 3685, test accuracy 0.981\n",
      "step 3690, test accuracy 0.975\n",
      "step 3695, test accuracy 0.981\n",
      "step 3700, test accuracy 0.978\n",
      "step 3705, test accuracy 0.981\n",
      "step 3710, test accuracy 0.977\n",
      "step 3715, test accuracy 0.982\n",
      "step 3720, test accuracy 0.977\n",
      "step 3725, test accuracy 0.984\n",
      "step 3730, test accuracy 0.974\n",
      "step 3735, test accuracy 0.985\n",
      "step 3740, test accuracy 0.975\n",
      "step 3745, test accuracy 0.985\n",
      "step 3750, test accuracy 0.974\n",
      "step 3755, test accuracy 0.982\n",
      "step 3760, test accuracy 0.977\n",
      "step 3765, test accuracy 0.983\n",
      "step 3770, test accuracy 0.977\n",
      "step 3775, test accuracy 0.984\n",
      "step 3780, test accuracy 0.975\n",
      "step 3785, test accuracy 0.97\n",
      "step 3790, test accuracy 0.978\n",
      "step 3795, test accuracy 0.97\n",
      "step 3800, test accuracy 0.977\n",
      "step 3805, test accuracy 0.969\n",
      "step 3810, test accuracy 0.976\n",
      "step 3815, test accuracy 0.975\n",
      "step 3820, test accuracy 0.977\n",
      "step 3825, test accuracy 0.977\n",
      "step 3830, test accuracy 0.977\n",
      "step 3835, test accuracy 0.975\n",
      "step 3840, test accuracy 0.98\n",
      "step 3845, test accuracy 0.976\n",
      "step 3850, test accuracy 0.981\n",
      "step 3855, test accuracy 0.973\n",
      "step 3860, test accuracy 0.981\n",
      "step 3865, test accuracy 0.973\n",
      "step 3870, test accuracy 0.98\n",
      "step 3875, test accuracy 0.973\n",
      "step 3880, test accuracy 0.981\n",
      "step 3885, test accuracy 0.974\n",
      "step 3890, test accuracy 0.98\n",
      "step 3895, test accuracy 0.977\n",
      "step 3900, test accuracy 0.982\n",
      "step 3905, test accuracy 0.978\n",
      "step 3910, test accuracy 0.982\n",
      "step 3915, test accuracy 0.977\n",
      "step 3920, test accuracy 0.983\n",
      "step 3925, test accuracy 0.975\n",
      "step 3930, test accuracy 0.985\n",
      "step 3935, test accuracy 0.975\n",
      "step 3940, test accuracy 0.984\n",
      "step 3945, test accuracy 0.974\n",
      "step 3950, test accuracy 0.984\n",
      "step 3955, test accuracy 0.976\n",
      "step 3960, test accuracy 0.983\n",
      "step 3965, test accuracy 0.977\n",
      "step 3970, test accuracy 0.984\n",
      "step 3975, test accuracy 0.977\n",
      "step 3980, test accuracy 0.971\n",
      "step 3985, test accuracy 0.977\n",
      "step 3990, test accuracy 0.971\n",
      "step 3995, test accuracy 0.975\n",
      "step 4000, test accuracy 0.971\n",
      "step 4005, test accuracy 0.977\n",
      "step 4010, test accuracy 0.974\n",
      "step 4015, test accuracy 0.975\n",
      "step 4020, test accuracy 0.975\n",
      "step 4025, test accuracy 0.976\n",
      "step 4030, test accuracy 0.977\n",
      "step 4035, test accuracy 0.979\n",
      "step 4040, test accuracy 0.976\n",
      "step 4045, test accuracy 0.982\n",
      "step 4050, test accuracy 0.973\n",
      "step 4055, test accuracy 0.984\n",
      "step 4060, test accuracy 0.974\n",
      "step 4065, test accuracy 0.981\n",
      "step 4070, test accuracy 0.972\n",
      "step 4075, test accuracy 0.98\n",
      "step 4080, test accuracy 0.974\n",
      "step 4085, test accuracy 0.981\n",
      "step 4090, test accuracy 0.975\n",
      "step 4095, test accuracy 0.981\n",
      "step 4100, test accuracy 0.978\n",
      "step 4105, test accuracy 0.981\n",
      "step 4110, test accuracy 0.977\n",
      "step 4115, test accuracy 0.981\n",
      "step 4120, test accuracy 0.976\n",
      "step 4125, test accuracy 0.985\n",
      "step 4130, test accuracy 0.974\n",
      "step 4135, test accuracy 0.985\n",
      "step 4140, test accuracy 0.975\n",
      "step 4145, test accuracy 0.984\n",
      "step 4150, test accuracy 0.974\n",
      "step 4155, test accuracy 0.982\n",
      "step 4160, test accuracy 0.978\n",
      "step 4165, test accuracy 0.984\n",
      "step 4170, test accuracy 0.977\n",
      "step 4175, test accuracy 0.984\n",
      "step 4180, test accuracy 0.975\n",
      "step 4185, test accuracy 0.971\n",
      "step 4190, test accuracy 0.977\n",
      "step 4195, test accuracy 0.969\n",
      "step 4200, test accuracy 0.977\n",
      "step 4205, test accuracy 0.971\n",
      "step 4210, test accuracy 0.975\n",
      "step 4215, test accuracy 0.976\n",
      "step 4220, test accuracy 0.978\n",
      "step 4225, test accuracy 0.977\n",
      "step 4230, test accuracy 0.977\n",
      "step 4235, test accuracy 0.975\n",
      "step 4240, test accuracy 0.98\n",
      "step 4245, test accuracy 0.974\n",
      "step 4250, test accuracy 0.982\n",
      "step 4255, test accuracy 0.973\n",
      "step 4260, test accuracy 0.981\n",
      "step 4265, test accuracy 0.972\n",
      "step 4270, test accuracy 0.981\n",
      "step 4275, test accuracy 0.973\n",
      "step 4280, test accuracy 0.98\n",
      "step 4285, test accuracy 0.975\n",
      "step 4290, test accuracy 0.981\n",
      "step 4295, test accuracy 0.978\n",
      "step 4300, test accuracy 0.981\n",
      "step 4305, test accuracy 0.977\n",
      "step 4310, test accuracy 0.983\n",
      "step 4315, test accuracy 0.977\n",
      "step 4320, test accuracy 0.984\n",
      "step 4325, test accuracy 0.975\n",
      "step 4330, test accuracy 0.985\n",
      "step 4335, test accuracy 0.975\n",
      "step 4340, test accuracy 0.984\n",
      "step 4345, test accuracy 0.974\n",
      "step 4350, test accuracy 0.983\n",
      "step 4355, test accuracy 0.977\n",
      "step 4360, test accuracy 0.983\n",
      "step 4365, test accuracy 0.977\n",
      "step 4370, test accuracy 0.983\n",
      "step 4375, test accuracy 0.976\n",
      "step 4380, test accuracy 0.971\n",
      "step 4385, test accuracy 0.977\n",
      "step 4390, test accuracy 0.971\n",
      "step 4395, test accuracy 0.977\n",
      "step 4400, test accuracy 0.969\n",
      "step 4405, test accuracy 0.976\n",
      "step 4410, test accuracy 0.974\n",
      "step 4415, test accuracy 0.976\n",
      "step 4420, test accuracy 0.975\n",
      "step 4425, test accuracy 0.975\n",
      "step 4430, test accuracy 0.976\n",
      "step 4435, test accuracy 0.98\n",
      "step 4440, test accuracy 0.977\n",
      "step 4445, test accuracy 0.983\n",
      "step 4450, test accuracy 0.974\n",
      "step 4455, test accuracy 0.982\n",
      "step 4460, test accuracy 0.973\n",
      "step 4465, test accuracy 0.981\n",
      "step 4470, test accuracy 0.972\n",
      "step 4475, test accuracy 0.98\n",
      "step 4480, test accuracy 0.974\n",
      "step 4485, test accuracy 0.981\n",
      "step 4490, test accuracy 0.977\n",
      "step 4495, test accuracy 0.981\n",
      "step 4500, test accuracy 0.978\n",
      "step 4505, test accuracy 0.982\n",
      "step 4510, test accuracy 0.977\n",
      "step 4515, test accuracy 0.982\n",
      "step 4520, test accuracy 0.975\n",
      "step 4525, test accuracy 0.985\n",
      "step 4530, test accuracy 0.974\n",
      "step 4535, test accuracy 0.984\n",
      "step 4540, test accuracy 0.974\n",
      "step 4545, test accuracy 0.985\n",
      "step 4550, test accuracy 0.975\n",
      "step 4555, test accuracy 0.982\n",
      "step 4560, test accuracy 0.977\n",
      "step 4565, test accuracy 0.985\n",
      "step 4570, test accuracy 0.976\n",
      "step 4575, test accuracy 0.984\n",
      "step 4580, test accuracy 0.976\n",
      "step 4585, test accuracy 0.969\n",
      "step 4590, test accuracy 0.976\n",
      "step 4595, test accuracy 0.971\n",
      "step 4600, test accuracy 0.977\n",
      "step 4605, test accuracy 0.973\n",
      "step 4610, test accuracy 0.976\n",
      "step 4615, test accuracy 0.976\n",
      "step 4620, test accuracy 0.976\n",
      "step 4625, test accuracy 0.978\n",
      "step 4630, test accuracy 0.979\n",
      "step 4635, test accuracy 0.976\n",
      "step 4640, test accuracy 0.981\n",
      "step 4645, test accuracy 0.974\n",
      "step 4650, test accuracy 0.983\n",
      "step 4655, test accuracy 0.974\n",
      "step 4660, test accuracy 0.982\n",
      "step 4665, test accuracy 0.973\n",
      "step 4670, test accuracy 0.98\n",
      "step 4675, test accuracy 0.973\n",
      "step 4680, test accuracy 0.981\n",
      "step 4685, test accuracy 0.975\n",
      "step 4690, test accuracy 0.981\n",
      "step 4695, test accuracy 0.978\n",
      "step 4700, test accuracy 0.981\n",
      "step 4705, test accuracy 0.977\n",
      "step 4710, test accuracy 0.982\n",
      "step 4715, test accuracy 0.977\n",
      "step 4720, test accuracy 0.984\n",
      "step 4725, test accuracy 0.974\n",
      "step 4730, test accuracy 0.985\n",
      "step 4735, test accuracy 0.975\n",
      "step 4740, test accuracy 0.985\n",
      "step 4745, test accuracy 0.974\n",
      "step 4750, test accuracy 0.982\n",
      "step 4755, test accuracy 0.977\n",
      "step 4760, test accuracy 0.983\n",
      "step 4765, test accuracy 0.977\n",
      "step 4770, test accuracy 0.984\n",
      "step 4775, test accuracy 0.975\n",
      "step 4780, test accuracy 0.97\n",
      "step 4785, test accuracy 0.978\n",
      "step 4790, test accuracy 0.97\n",
      "step 4795, test accuracy 0.977\n",
      "step 4800, test accuracy 0.969\n",
      "step 4805, test accuracy 0.976\n",
      "step 4810, test accuracy 0.975\n",
      "step 4815, test accuracy 0.977\n",
      "step 4820, test accuracy 0.977\n",
      "step 4825, test accuracy 0.977\n",
      "step 4830, test accuracy 0.975\n",
      "step 4835, test accuracy 0.98\n",
      "step 4840, test accuracy 0.976\n",
      "step 4845, test accuracy 0.981\n",
      "step 4850, test accuracy 0.973\n",
      "step 4855, test accuracy 0.981\n",
      "step 4860, test accuracy 0.973\n",
      "step 4865, test accuracy 0.98\n",
      "step 4870, test accuracy 0.973\n",
      "step 4875, test accuracy 0.981\n",
      "step 4880, test accuracy 0.974\n",
      "step 4885, test accuracy 0.98\n",
      "step 4890, test accuracy 0.977\n",
      "step 4895, test accuracy 0.982\n",
      "step 4900, test accuracy 0.978\n",
      "step 4905, test accuracy 0.982\n",
      "step 4910, test accuracy 0.977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 4915, test accuracy 0.983\n",
      "step 4920, test accuracy 0.975\n",
      "step 4925, test accuracy 0.985\n",
      "step 4930, test accuracy 0.975\n",
      "step 4935, test accuracy 0.984\n",
      "step 4940, test accuracy 0.974\n",
      "step 4945, test accuracy 0.984\n",
      "step 4950, test accuracy 0.976\n",
      "step 4955, test accuracy 0.983\n",
      "step 4960, test accuracy 0.977\n",
      "step 4965, test accuracy 0.984\n",
      "step 4970, test accuracy 0.977\n",
      "step 4975, test accuracy 0.971\n",
      "step 4980, test accuracy 0.977\n",
      "step 4985, test accuracy 0.971\n",
      "step 4990, test accuracy 0.975\n",
      "step 4995, test accuracy 0.971\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as session: \n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Initialized')\n",
    "    \n",
    "    # Saver setup\n",
    "    saver = tf.train.Saver()\n",
    "    save_dir = 'checkpoints_ellipsesparalel_highorder/'\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    save_path = os.path.join(save_dir, 'model_angle2')\n",
    "\n",
    "    \n",
    "    # Train the model\n",
    "    for step in range(num_steps):\n",
    "        # Logging every 100th iteration in the training process.\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size_train) % (y_train.shape[0] - batch_size_train)\n",
    "        \n",
    "        ## Lets do validation\n",
    "        offset_valid = (step * batch_size_valid) % (y_valid.shape[0] - batch_size_valid)\n",
    "\n",
    "        # Generate a minibatch.\n",
    "        batch_data = X_train[offset:(offset + batch_size_train), :]\n",
    "        batch_labels = y_train[offset:(offset + batch_size_train), :]\n",
    "        if step%5 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={x:batch_data, y_: batch_labels, keep_prob: 1.0})\n",
    "            print(\"step %d, training accuracy %g\"%(step, train_accuracy))\n",
    "            \n",
    "        if step%100 == 0:\n",
    "            ## Some test\n",
    "            # Generate a test minibatch.\n",
    "            batch_data_valid = X_valid[offset_valid:(offset_valid + batch_size_valid), :]\n",
    "            batch_labels_valid = y_valid[offset_valid:(offset_valid + batch_size_valid), :]\n",
    "            valid_accuracy = accuracy.eval(feed_dict={x:batch_data_valid, y_: batch_labels_valid, keep_prob: 1.0})\n",
    "            valid_accuracy_minibatches.append(valid_accuracy)\n",
    "            print(\"\\033[1m step %d, validation accuracy \\033[0;0m %g\"%(step, valid_accuracy))\n",
    "            \n",
    "            # Save when there is an improvement \n",
    "            if valid_accuracy > best_validation_accuracy:\n",
    "                print(\"\\033[1m The validation accuracy has improved from the last checkpoint \\033[0;0m\")\n",
    "                best_validation_accuracy = valid_accuracy\n",
    "                best_validation_accuracy_step = step\n",
    "                saver.save(sess = session, save_path=save_path)\n",
    "            else:\n",
    "                print(\"\\033[1m The validation accuracy DID NOT improved from the last checkpoint \\033[0;0m\")\n",
    "\n",
    "            \n",
    "        train_step.run(feed_dict={x: batch_data, y_: batch_labels, keep_prob: 0.5})\n",
    "        \n",
    "        \n",
    "    # Evaulate our accuracy on the test data\n",
    "    # Test the model\n",
    "    for step in range(num_steps):\n",
    "        offset_test = (step * batch_size_test) % (y_test.shape[0] - batch_size_test)\n",
    "\n",
    "        # Generate a minibatch.\n",
    "        batch_data_test = X_test[offset_test:(offset_test + batch_size_test), :]\n",
    "        batch_labels_test = y_test[offset_test:(offset_test + batch_size_test), :]\n",
    "        test_accuracy = accuracy.eval(feed_dict={x:batch_data_test, y_: batch_labels_test, keep_prob: 1.0})\n",
    "        test_accuracy_minibatches.append(test_accuracy)\n",
    "        \n",
    "        if step%5 == 0:\n",
    "            print(\"step %d, test accuracy %g\"%(step, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average test accuracy is 93.36999445\n"
     ]
    }
   ],
   "source": [
    "print(\"The average test accuracy is \"+str(sum(test_accuracy_minibatches)/len(test_accuracy_minibatches)*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
